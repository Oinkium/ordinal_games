\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc}

\usepackage{graphicx} % support the \includegraphics command and options

\usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)\prefix\t$.
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
\usepackage{mathtools} % for the all important \coloneqq symbol
\usepackage{url} % for \url
\usepackage{IEEEtrantools} % for \IEEEeqnarray
\usepackage{pbox} % for \pbox

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%% Font things %%
\usepackage{amssymb}
\usepackage{cmll} % Linear logic symbols!
\usepackage{bm} % for bold Greek letters

%% Get the sqsubsetneqq character from the mathabx package
\DeclareFontFamily{U}{mathb}{\hyphenchar\font45}
\DeclareFontShape{U}{mathb}{m}{n}{
      <5> <6> <7> <8> <9> <10> gen * mathb
      <10.95> mathb10 <12> <14.4> <17.28> <20.74> <24.88> mathb12
      }{}
\DeclareSymbolFont{mathb}{U}{mathb}{m}{n}

\DeclareMathSymbol{\sqsubsetneq}    {3}{mathb}{"88}
\DeclareMathSymbol{\varsqsubsetneq} {3}{mathb}{"8A}
\DeclareMathSymbol{\varsqsubsetneqq}{3}{mathb}{"92}
\DeclareMathSymbol{\sqsubsetneqq}   {3}{mathb}{"90}

%% Lists %%
\usepackage{enumerate}

%% Graphics %%
\usepackage{tikz}
\usetikzlibrary{cd}
\usetikzlibrary{patterns}
\usetikzlibrary{calc}

%% Theorems! %%
\usepackage{amsthm}
\theoremstyle{plain} % Theorems, lemmas, propositions etc.
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{construction}[theorem]{Construction}
\theoremstyle{definition} % Definitions etc.  Remarks too, because I don't like the way the 'remark' style looks.
\newtheorem{definition}[theorem]{Definition}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{question}[theorem]{Question}

\newtheoremstyle{note} {3pt} {3pt} {\itshape} {} {\itshape} {:} {.5em} {} % For short notes
\theoremstyle{note}
\newtheorem{note}[theorem]{Note}

%% Exercises and answers %%
\usepackage{answers}

\newtheoremstyle{exercisestyle}% name
  {6pt}   % ABOVESPACE
  {6pt}   % BELOWSPACE
  {\itshape}  % BODYFONT
  {0pt}       % INDENT (empty value is the same as 0pt)
  {\bfseries} % HEADFONT
  {.}         % HEADPUNCT
  {3pt} % HEADSPACE
  {}          % CUSTOM-HEAD-SPEC

\theoremstyle{exercisestyle}
\newtheorem{exercise}{Exercise}
\newtheorem{answerthm}{Exercise}

\Newassociation{answer}{answerthm}{answers}
\newcommand{\answerthmparams}{}

%% Changes to enumerate things so they look better %%\sigma$

\makeatletter
\def\enumfix{%
\if@inlabel
 \noindent \par\nobreak\vskip-\topsep\hrule\@height\z@
\fi}

\let\olditemize\itemize
\def\itemize{\enumfix\olditemize}
\let\oldenumerate\enumerate
\def\enumerate{\enumfix\oldenumerate}

%% Random crap %%
\usepackage{xifthen}

\makeatletter
\def\thm@space@setup{%
  \thm@preskip=\parskip \thm@postskip=0pt
}
\makeatother

\makeatletter
\newcommand*{\relrelbarsep}{.386ex}
\newcommand*{\relrelbar}{%
  \mathrel{%
    \mathpalette\@relrelbar\relrelbarsep
  }%
}
\newcommand*{\@relrelbar}[2]{%
  \raise#2\hbox to 0pt{$\m@th#1\relbar$\hss}%
  \lower#2\hbox{$\m@th#1\relbar$}%
}
\providecommand*{\rightrightarrowsfill@}{%
  \arrowfill@\relrelbar\relrelbar\rightrightarrows
}
\providecommand*{\leftleftarrowsfill@}{%
  \arrowfill@\leftleftarrows\relrelbar\relrelbar
}
\providecommand*{\xrightrightarrows}[2][]{%
  \ext@arrow 0359\rightrightarrowsfill@{#1}{#2}%
}
\providecommand*{\xleftleftarrows}[2][]{%
  \ext@arrow 3095\leftleftarrowsfill@{#1}{#2}%
}
\makeatother

\newcommand{\catname}[1]{{\normalfont\textbf{#1}}}
\newcommand{\Rings}{\catname{CRing}}
\newcommand{\CAT}{\catname{CAT}}
\newcommand{\Top}{\catname{Top}}
\newcommand{\Set}{\catname{Set}}
\newcommand{\Cont}{\catname{Cont}}
\newcommand{\Sch}{\catname{Sch}}
\newcommand{\Rel}{\catname{Rel}}
\newcommand{\Mod}[1][]{\ifthenelse{\isempty{#1}}{\catname{Mod}}{#1\catname{mod}}}
\DeclareMathOperator{\sh}{Sh}
\newcommand{\Sh}[1][]{\ifthenelse{\isempty{#1}}{\sh}{\sh(#1)}}
\newcommand{\map}[3]{#2\xrightarrow{#1} #3}
\newcommand*\from{\colon}
\newcommand{\cmap}[3]{#1\from{}#2\to{}#3}
\newcommand\oppcat[1]{#1^{\mathrm{op}}}
\DeclareRobustCommand{\vmap}[3] {\begin{tikzcd} #2 \arrow[d, "#1"] \\ #3 \end{tikzcd}}
\newcommand{\partref}[1]{(\ref{#1})}
\newcommand{\intgrpd}[4] {#1 \xrightrightarrows[#3]{#4} #2}
\DeclareRobustCommand{\bigintgrpd}[4] {\begin{tikzcd}[ampersand replacement=\&] #1 \arrow[r, shift left=0.5ex, "#3"] \arrow[r, shift right=0.5ex, "#4"'] \& #2 \end{tikzcd}}

\usepackage{xspace}

\newcommand{\etale}{\'{e}tale\xspace}
\newcommand{\Etale}{\'{E}tale\xspace}

\def \inv {^{-1}}

\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\op}{op}
\DeclareMathOperator{\pr}{pr}
\DeclareMathOperator{\pre}{{pre}}
\DeclareMathOperator{\et}{{\acute{e}t}}

\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Spec}{Spec}

\DeclareMathOperator{\ol}{ol}

\def\presuper#1#2%
  {\mathop{}%
   \mathopen{\vphantom{#2}}^{#1}%
   \kern-\scriptspace%
   #2}
\def\presub#1#2%
  {\mathop{}%
   \mathopen{\vphantom{#2}}_{#1}%
   \kern-\scriptspace%
   #2}

%% Our things %%

\newcommand{\neggame}[1]{\presuper{\perp}{#1}}
\newcommand{\tensor}{\otimes}
\newcommand{\sequoid}{\oslash}
\newcommand{\varsequoid}{\vartriangleleft}
\renewcommand{\implies}{\multimap}
\newcommand{\comp}[2]{#1 \circ #2}
\newcommand{\cprd}{\sqcup}
\newcommand{\G}{\mathcal G}
\newcommand{\suchthat}{\;\colon\;}
\newcommand{\varsuchthat}{\;\mid\;}
\newcommand{\esuchthat}{\;.\;}
\newcommand{\OP}{\{O,P\}}
\renewcommand{\L}{\mathcal L}
\newcommand{\F}{\mathcal F}
\newcommand{\s}{\mathfrak s}
\renewcommand{\t}{\mathfrak t}
\newcommand{\emptyplay}{\epsilon}
\newcommand{\bracketed}[1]{\left({#1}\right)}
\newcommand{\bneggame}[1]{{\bracketed{\neggame{#1}}}}
\newcommand{\prefix}{\sqsubseteq}
\newcommand{\pprefix}{\sqsubsetneqq}
\renewcommand{\ss}{\mathbf{s}}
\newcommand{\pfun}{\rightharpoonup}
\newcommand{\grel}[1]{\underline{#1}}
\DeclareMathOperator{\length}{length}
\renewcommand{\b}{\mathfrak b}
\renewcommand{\r}{\mathfrak r}
\newcommand{\bbeta}{{\bm{\beta}}}
\newcommand{\st}{{\Sigma^*}}
\renewcommand{\S}{{\mathfrak{S}}}

\let\oldemptyset\emptyset
\let\emptyset\varnothing

%%% END Article customizations

\begin{document}

\section{Introduction}

These are games with ordinal sequences of moves.

TODO: Talk about what they are and why we are interested, being careful to point out that our $\omega+1$ games correspond to games with winning conditions.

\section{Our starting category of games}

Before studying games with transfinite sequences of moves, we shall illustrate some of the choices we have made by defining a category of games with finite sequences of moves.  We have chosen these definitions because they extend particularly well to the transfinite case.  

\subsection{Games and strategies}

We shall use the notation introduced in \cite{abramskyjagadeesangames} to describe games.  All our games $A$ will have, at their heart, the following three pieces of information:
\begin{itemize}
  \item A set $M_A$ of possible moves
  \item A function $\cmap{\lambda_A}{M_A}{\OP}$ assigning to each move the player who is allowed to make that move
  \item A prefix-closed set $P_A\subset M_A^*$ of finite sequences of moves.
\end{itemize}
We shall normally insist on an \emph{alternating condition} on $P_A$:
\begin{description}
  \item[Alternating condition] If $a,b\in M_A$ are moves and $s\in M_A^*$ is a sequence of moves such that $sa, sab\in P_A$, then $\lambda_A(a)=\neg\lambda_A(b)$.
\end{description}

As in \cite{abramskyjagadeesangames}, we identify a \emph{strategy} for a game $A$ with the set of sequences of moves that can occur when player $P$ is playing according to that strategy so that a typical definition of a (partial) strategy might be a set $\sigma\subset P_A$ such that (for all $s\in M_A^*, a,b\in M_A$):
\begin{itemize}
  \item $\emptyplay\in\sigma$ (ensures that $\sigma$ is non-empty)
  \item If $sa\in\sigma$, $\lambda_A(a)=P$ and $sab\in P_A$ then $sab\in\sigma$ ($\sigma$ contains all legal replies by player $O$)
  \item If $s,sa,sb\in\sigma$ and $\lambda_A(a)=P$ then $a=b$ ($\sigma$ contains at most one legal reply by player $P$)
\end{itemize}

We can impose additional constraints on $\sigma$ that will ensure that $\sigma$ is total, strict, history free and so on.  The definition given immediately above is not the only definition of a strategy found in the literature, however.  For example, the games described in \cite{abramskyjagadeesangames} have the curious property that the set $P_A$ may contain plays that cannot actually occur when $A$ is being played; in particular, all plays must start with a move by player $O$, but the set $P_A$ may contain positions that start with a $P$-move.  These plays do not affect the strategies for $A$, but they might come into play if we perform operations on $A$ such as forming the negation $\neg A$ or the implication $A\implies B$.  

This behaviour is made implicit in Abramsky and Jagadeesan's definitions, which do not impose any conditions upon the set $P_A$ beyond the basic alternation condition given above, but which mandate that any play occurring \emph{in a strategy} must begin with an $O$-move.  For the sake of clarity, we adopt a different, but completely equivalent, approach.  For a game $A$, we define a set $L_A$, regarded as the set of \emph{legal plays} occurring in $P_A$.  In some games models, such as that found in \cite{blassgames}, $L_A$ may be defined to be the whole of $P_A$, while in \cite{abramskyjagadeesangames} it is defined to be that subset of $P_A$ consisting of plays that begin with an $O$-move.

The point of specifying $L_A$ separately is that it allows us to unify the definitionn of a \emph{strategy}, while making clearer the behaviour observed above, whereby certain plays in $P_A$ may not occur `in normal play'; this behaviour was previously only implicit in the definition of a strategy.  Our unified definition then becomes:

\begin{definition}
  If $A=(M_A,\lambda_A,P_A)$ is a game and $L_A$ is its associated set of legal plays (in a particular games model) then a (partial) \emph{strategy} for $A$ is a subset $\sigma\subset L_A$ such that for all $s\in L_A$ and all $a, b\in M_A$:
  \begin{itemize}
    \item $\emptyplay\in\sigma$
    \item If $s\in\sigma$ and $a$ is an $O$-move, and if $sa\in L_A$, then $sa\in\sigma$
    \item If $s\in\sigma$ and $a,b$ are $P$-moves, and if $sa,sb\in\sigma$, then $a=b$
  \end{itemize}
\end{definition}

\subsection{Positive and negative games, ownership of plays and connectives}

Abramsky-Jagadeesan games, as described in \cite{abramskyjagadeesangames}, may admit both plays that start with a $P$-move and plays that start with an $O$-move.  Other games models, such as those found in \cite{blassgames} and \cite{curiengames}, are more restrictive.  The games in \cite{curiengames} only contain plays starting with an $O$-move.  The plays in \cite{blassgames} may start with either a $P$-move or an $O$-move, but a play starting with a $P$-move and a play starting with an $O$-move may not occur in the same game.

\begin{definition}
  We say that a game $A=(M_A,\lambda_A,P_A)$ is \emph{positive} if every play in $P_A$ begins with a $P$-move.
  We say that $A$ is \emph{negative} if every play in $P_A$ begins with an $O$-move.
\end{definition}

So the Curien model found in \cite{curiengames} admits only negative games, the Blass model in \cite{blassgames} admits positive and negative games, while the Abramsky-Jagadeesan model found in \cite{abramskyjagadeesangames} admits not only positive and negative games, but also games that are neither negative nor positive.  We shall now examine the reasons for and drawbacks of each of these choices.

The earliest games model, found in \cite{conwaygames}, did not include a definition of which player is to move at a given position; rather, games are defined recursively as pairs of games $\{L|R\}$, where $L$ represents the positions that the left player may move into, while $R$ represents the positions that the rigth player may move into.  Blass's definition departs completely from this tradition; now, at every position $s$ only one of the two players is allowed to move; extending this logic on to the empty position $\emptyplay$, it follows that all games are either positive or negative.  This property means that we may freely define $L_A=P_A$, since there is never any question about whose turn it is to play.  By contrast, if we were to define $L_A=P_A$ for Abramsky-Jagadeesan games, then a strategy might end up containing two branches, one of plays beginning with an $O$-move and one of plays beginning with a $P$-move, which is undesirable.  The alternative definition of $L_A$ avoids this problem.

In the case of a Blass game $A$, we may define a function $\zeta_A\colon P_A\to\OP$ that says which player owns each play; the idea is that if we are in position $s$, then the next player to move is given by $\neg\zeta_A(s)$; i.e., the opposing player to the player who has just made the move.  One might want to define $\zeta_A$ by setting $\zeta_A(sa)=\lambda_A(a)$, so that ownership of a play is decided by who has made the last move in the play, but this definition does not extend in an obvious way to the empty position $\emptyplay$ (and, as we shall see in the next chapter, it does not extend to plays over limit ordinals).  In this case, $\zeta_A(\emptyplay)$ is part of the game's data, and it determines whether the game is positive or negative: if $\zeta_A(\emptyplay) = P$ then all plays must start with an $O$-move, and the game is negative -- and vice versa.

An important question then arises: how should we extend the function $\zeta_A$ to games formed from connectives?  The solution adopted by Blass is to use binary conjunctions to deduce the ownership of a play from the ownership of the restrictions of that play to the two component games.  In the case of the tensor product $A\tensor B$ of two games $A$ and $B$, we define $\cmap{\zeta_{A\tensor B}}{P_{A\tensor B}}{\OP}$ by setting
\[
  \zeta_{A\tensor B}(s) = (\zeta_A(s\vert_A) \wedge \zeta_B(s\vert_B))
  \]
where $\cmap{\wedge}{\OP\times \OP}{\OP}$ is as in Figure \ref{truthtables}.

\begin{figure}[h]
  \begin{center}
    $\begin{array}{cc|c}
      a & b & a \wedge b \\
      \hline
      O & O & O \\
      O & P & O \\
      P & O & O \\
      P & P & P
    \end{array}$
    \quad
    $\begin{array}{cc|c}
      a & b & a \vee b \\
      \hline
      O & O & O \\
      O & P & P \\
      P & O & P \\
      P & P & P
    \end{array}$
    \quad
    $\begin{array}{cc|c}
      a & b & a \Rightarrow b \\
      \hline
      O & O & P \\
      O & P & P \\
      P & O & O \\
      P & P & P
    \end{array}$
    \caption{Truth tables for binary conjunctions on $\OP$}
    \label{truthtables}
  \end{center}
\end{figure}

Similarly, we may extend $\zeta$ to the implication $A\implies B$ and the par $A\parr B$ by setting
\begin{align*}
  \zeta_{A\implies B}(s)=(s\vert_A\Rightarrow s\vert_B)\\
  \zeta_{A\parr B}(s) = (s\vert_A \vee s\vert_B)
\end{align*}

Note that if we use these definitions then the owner $\zeta_C(sa)$ of a play $sa$ might not correspond to the player $\lambda_C(a)$ who played the last move $a$.  For example, let $A,B$ be two positive games and form their tensor product $A\tensor B$.  Then we have
\[
  \zeta_{A\tensor B}(\emptyplay) = (\zeta_A(\emptyplay) \wedge \zeta_B(\emptyplay)) = O \wedge O = O
  \]
and so $A\tensor B$ is a positive game.  Player $P$ plays an opening move in one of the two games - let us say she plays the move $a$ in the game $A$.  But then we have
\[
  \zeta_{A\tensor B}(a) = (\zeta_A(a) \wedge \zeta_B(\emptyplay)) = P \wedge O = O
  \]
In other words, it is still player $P$'s turn to play!  Blass embrace this possibility and allows player $P$ to make these two moves.  In his paper, he introduces the notions of \emph{strict} and \emph{relaxed} games, where the strict games are the objects of study but the relaxed games are often used since they allow more manipulations.  In this case, the game $A\tensor B$ is defined as a relaxed game that might not satisfy the alternating condition; in the process of converting it into a strict game, these two opening moves by player $P$ are combined into a single move.

This `double move' can only occur at the start of the game, and Blass treats it as a special case in his proofs.  Perhaps unsurprisingly, this inconsistency causes major problems if we try to compose strategies.  We do not get an associative composition of strategies for $A\implies B$ with strategies for $B\implies C$ and so we do not get a categorical semantics.  An example of the failure of associativity in Blass's games model is given towards the end of \cite{abramskyjagadeesangames}.

By contrast, Abramsky-Jagadeesan games may admit moves by both players at the same position (specifically, at the beginning of the game, before any moves have been played), but this does not cause problems since we insist that our legal plays start with an $O$-move and be strictly alternating.  The authors of \cite{abramskyjagadeesangames} note that their model can be considered as an intermediate between Conway's games, where the position tells you nothing about which player is to move, and Blass games, where the position completely determines which player is to move.  In Abramsky-Jagadeesan games, one can deduce which player is to move (by looking at which player made the last move) in every position except the empty starting position.

In the Abramsky-Jagadeesan model, a positive game is an immediate win to player $P$, since player $O$ has no legal move to start the game off.  As we noted before, this does not mean that the content of a positive game is meaningless, since we can use connectives to `unlock' these illegal plays.  For example, if $Q$ is a positive game and $N$ is a negative game then $Q\parr N$ is a negative game, and the possible positions in $Q$ are now all achievable.  

Curien's game model (\cite{curiengames}) is similar to Abramsky's and Jagadeesan's, but involves only negative games.  The only slight problem is that negative Abramsky-Jagadeesan games are not closed under implication: if $N,L$ are negative games then $N\implies L$ may be neither negative nor positive.  We may fix this by modifying the definition of $N\implies L$ so that we delete from $P_{N\implies L}$ all plays that start with a $P$-move - or, equivalently, by requiring that all plays start in $L$.  This is the approach taken in \cite{martinsthesis}, where it fits well with the paper's treatment of the \emph{sequoid} operator $\sequoid$, which is a version of the tensor product that has been modified so that play is required to start in the left-hand game.

We shall adopt elements of both the Blass and the Abramsky-Jagadeesan games models; specifically, we shall use Blass's games and Abramsky-Jagadeesan's strategies.  This means that our games model will be more restrictive than either the Blass or the Abramsky-Jagadeesan models, but this lack of flexibility will be just what we need in order to extend these games over the transfinite ordinals.  We will later consider ways we can relax our model to recover Abramsky and Jagadeesan's games model.

\subsection{Our definition of games and strategies}

\begin{definition}
  A \emph{game} is a triple $(M_A,\lambda_A,\zeta_A,P_A)$ where
  \begin{itemize}
    \item $M_A$ is a set of moves,
    \item $\cmap{\lambda_A}{M_A}{\OP}$ is a function that assigns a player to each move,
    \item $P_A\subset M_A^*$ is a non-empty prefix-closed set of plays that can occur in the game and
    \item $\cmap{\zeta_A}{P_A}{\OP}$ is a function that assigns a player to each position
  \end{itemize}
  such that
  \begin{itemize}
    \item If $a\in M_A$ and $sa\in P_A$ then $\zeta_A(sa)=\lambda_A(a)$.
    \item If $a\in M_A$ and $sa\in P_A$ then $\zeta_A(s)=\neg\zeta_A(sa)$.
  \end{itemize}
\end{definition}

\begin{remark}[Notes on the definition]
  Given a game $A=(M_A,\lambda_A,\zeta_A,P_A)$, define $b_A=\neg\zeta_A(\emptyplay)$.  Then every play in $P_A$ must start with a $b_A$-move, so $A$ is either positive or negative.

  Note that $\zeta_A$ is now completely specified by $\lambda_A$ and $b_A$, so we could have specified our games mor efficiently by replacing $\zeta_A$ with $b_A$ in our definition, as done in \cite{martinsthesis}.  The slightly more unwieldy $\zeta_A$ will be useful when we come to extend our games over the ordinals, though, so we retain it.

  If $a\in M_A$ then we may recover $\lambda_A(a)$ from $\zeta_A$ so long as $a$ occurs in some play in $P_A$.  Since moves that can never be played do not affect the game at all, we do not really need $\lambda_A$ in our definition, but we keep it to make the connection to earlier work clearer.

  If $a\in M_A$ and $\lambda_A(a)=O$, we call $a$ an \emph{$O$-move}.  If $\lambda_A(a)=P$, we call $a$ a \emph{$P$-move}.  If $s\in P_A$ and $\zeta_A(s)=O$, we call $s$ an \emph{$O$-play} or \emph{$O$-position}.  If $\zeta_A(s)=P$, we call $s$ a \emph{$P$-play} or \emph{$P$-position}.

\end{remark}

We give the usual definition of a strategy as an appropriate subset of $P_A$, where we have identified the strategy with the set of all plays that can arise when player $P$ plays according to that strategy:

\begin{definition}
  Let $A=(M_A,\lambda_A,\zeta_A,P_A)$ be a game.  A \emph{strategy} for $A$ is a non-empty prefix-closed subset $\sigma\subset P_A$ such that:
  \begin{itemize}
    \item If $a\in P_A$ is an $O$-move and $s\in\sigma$ is a $P$-position such that $sa\in P_A$, then $sa\in\sigma$.
    \item If $s\in\sigma$ is an $O$-position and $a,b\in M_A$ are $P$-moves such that $sa,sb\in\sigma$, then $a=b$.
  \end{itemize}
\end{definition}

The definition above will be the most technically useful, but it is also convenient to give a strategy by a partial function that tells player $P$ which move to make in each $O$-position.  If we write $P_A^-=\zeta_A\inv(\{O\})$ for the set of all $O$-positions and $M_A^+=\lambda_A\inv(\{P\})$ for the set of all $P$-moves, then the strategy $\sigma$ above gives rise to a partial function $\hat\sigma\from P_A^-\pfun M_A^+$ given by:
\[
  \hat\sigma(s)=
  \begin{cases}
    a & \textrm{if $a\in M_A^+$ and $sa\in P_A$}\\
    \textrm{undefined} & \textrm{if $sb\not\in P_A$ for all $b\in M_A^+$}
  \end{cases}
  \]
The second condition on strategies tells us that this is well defined.  Going in the other direction, if we are given a partial function $f\from P_A^-\pfun M_A^+$  then we can define a strategy $\overline{f}$ by
\[
  \overline f = \{s\in M_A^*\suchthat \textrm{for all $ta\prefix s$ with $\zeta_A(t)=O$, $f(t)$ is defined and equal to $a$}\}
  \]

\subsection{Connectives}

Our definitions of connectives on games are as in \cite{blassgames}.

\begin{definition}
  Let $A=(M_A,\lambda_A,\zeta_A,P_A)$ be a game.  The negation of $A$, $\neggame{A}$, is the game formed by interchanging the roles of the two players.
  \begin{itemize}
    \item $M_{\bneggame A}=M_A$
    \item $\lambda_{\bneggame A} = \comp\neg{\lambda_A}$
    \item $\zeta_{\bneggame A} = \comp\neg{\zeta_A}$
    \item $P_{\bneggame A} = P_A$
  \end{itemize}
\end{definition}

It follows immediately from the definitions that $\neggame A$ is a well formed game.

We now define the tensor product $A\tensor B$, the par $A\parr B$ and the linear implication $A\implies B$ of two games.  All these games are obtained by playing $A$ and $B$ in parallel, so they all have the same set of moves:
\[
  M_{A\tensor B} = M_{A\parr B} = M_{A\implies B} = M_A \cprd M_B
  \]

Ownership of moves is decided via the obvious copairing functions:
\begin{IEEEeqnarray*}{c}
  \lambda_{A\tensor B} = \lambda_{A\parr B} = \lambda_A \cprd \lambda_B\\
  \lambda_{A\implies B} = (\neg\circ\lambda_A) \cprd \lambda_B
\end{IEEEeqnarray*}

We define the set $P_A\|P_B$ to be the set of all plays in $(M_A \cprd M_B)^*$ whose $M_A$-component is a play from $P_A$ and whose $M_B$-component is a play from $P_B$:
\[
  P_A\|P_B = \{s\in (M_A\cprd M_B)^*\suchthat s\vert_A\in P_A,\; s\vert_B\in P_B\}
  \]

We are now in a position to define $\zeta_{A\tensor B},\zeta_{A\parr B},\zeta_{A\implies B}$ as functions $P_A\|P_B\to\OP$:
\begin{IEEEeqnarray*}{rCl}
  \zeta_{A\tensor B}(s) & = & \zeta_A(s\vert_A) \wedge \zeta_B(s\vert_B) \\
  \zeta_{A\parr B}(s) & = & \zeta_A(s\vert_A) \vee \zeta_B(s\vert_B) \\
  \zeta_{A\implies B}(s) & = & \zeta_A(s\vert_A) \Rightarrow \zeta_B(s\vert_B)
\end{IEEEeqnarray*}

(Here, $\wedge$, $\vee$ and $\Rightarrow$ are as in Figure \ref{truthtables}.)

As things stand, $P_A\|P_B$ is not a valid set of plays for our $\lambda$ and $\zeta$ functions.  The first problem is that $P_A\|P_B$ contains plays which are not alternating with respect to $\zeta_{A\tensor B},\zeta_{A\parr B},\zeta_{A\implies B}$.  The second problem is that the $\zeta$ and $\lambda$ functions do not always agree with one another.  For example, suppose that $Q,R$ are two positive games.  So we have $\zeta_Q(\emptyplay) = \zeta_R(\emptyplay) = O$.  Then $\zeta_{Q\tensor R}(\emptyplay) = O\wedge O = O$.  But now suppose that player $P$ can make an opening move $q$ in $Q$.  Then we have
\[
  \zeta_{Q\tensor R}(q) = \zeta_Q(q) \wedge \zeta_R(\emptyplay) = P \wedge O = O
  \]
but $\lambda_{Q\tensor R}(q) = P$.  

Our solution is to throw away some plays from $P_A\| P_B$ so that what remains satisfies the alternating condition and the condition on the $\lambda$ and $\zeta$ functions.

\begin{definition}
  Let $M$ be a set, let $P\subset M^*$ be prefix closed and let $\cmap{\lambda}{M}{\OP},\cmap{\zeta}{P}{\OP}$ be functions.  If $s\in P$, we say that $s$ is \emph{alternating with respect to $\zeta$} if the set of prefixes of $s$ satisfies the alternating condition: if $t,ta\prefix s$, then $\zeta(t) = \neg\zeta(ta)$.

  We say that $s$ is \emph{well formed with respect to $\lambda,\zeta$} if whenever $ta\prefix s$, for some $a\in M$, we have $\zeta(ta)=\lambda(a)$.

  Now let $A,B$ be games.  We define:
  \begin{IEEEeqnarray*}{rCl}
    P_{A\tensor B} & = & \left\{s\in P_A\|P_B \;\middle|\; \mbox{\pbox{\textwidth}{$s$ is alternating with respect to $\zeta_{A\tensor B}$ \\ $s$ is well formed with respect to $\zeta_{A\tensor B},\lambda_{A\tensor B}$}}\right\} \\
    P_{A\parr B} & = & \left\{s\in P_A\|P_B \;\middle|\; \mbox{\pbox{\textwidth}{$s$ is alternating with respect to $\zeta_{A\parr B}$ \\ $s$ is well formed with respect to $\zeta_{A\parr B},\lambda_{A\parr B}$}}\right\} \\
    P_{A\implies B} & = & \left\{s\in P_A\|P_B \;\middle|\; \mbox{\pbox{\textwidth}{$s$ is alternating with respect to $\zeta_{A\implies B}$ \\ $s$ is well formed with respect to $\zeta_{A\implies B},\lambda_{A\implies B}$}}\right\}
  \end{IEEEeqnarray*}
\end{definition}

\begin{definition}
  We define:
  \begin{IEEEeqnarray*}{cCc}
    A\tensor B & = & (M_{A\tensor B}, \lambda_{A\tensor B}, \zeta_{A\tensor B}, P_{A\tensor B}) \\
    A\parr B & = & (M_{A\parr B}, \lambda_{A\parr B}, \zeta_{A\parr B}, P_{A\parr B}) \\
    A\implies B & = & (M_{A\implies B}, \lambda_{A\implies B}, \zeta_{A\implies B}, P_{A\implies B})
  \end{IEEEeqnarray*}
\end{definition}

\begin{proposition}
  $A\tensor B$,$A\parr B$,$A\implies B$ are well formed games.  Moreover, $P_{A\tensor B}$ is the largest subset $X\subset P_A\|P_B$ such that $(M_{A\tensor B}, \lambda_{A\tensor B}, \zeta_{A\tensor B}, X)$ is a well formed game and similarly for the connectives $\parr$ and $\implies$.  
  \begin{proof}
    We will prove the proposition for $A\tensor B$; the other two cases are entirely similar.  Alternatively, observe that $A\parr B=\neggame{(\neggame A \tensor \neggame B)}$ and $A\implies B = \neggame A \parr B$.

    For $A\tensor B$, it suffices to show that $P_{A\tensor B}$ is alternating with respect to $\zeta_{A\tensor B}$, since every $s\in P_{A\tensor B}$ is well-formed by definition.  Suppose $s,sa\in P_{A\tensor B}$; then $s,sa\prefix sa$; since $sa$ is alternating with respect to $\zeta_{A\tensor B}$, it follows that $\zeta_{A\tensor B}(s) = \neg\zeta_{A\tensor B}(sa)$.

    For the second part of the proposition, suppose that $V\subset P_A\|P_B$ is prefix-closed and satisfies the alternating condition with respect to $\zeta_{A\tensor B}$ and that every $s\in V$ is well-formed with respect to $\lambda_{A\tensor B},\zeta_{A\tensor B}$.  We need to show that $V\subset P_{A\tensor B}$, for which it will suffice to show that every $s\in V$ is alternating.  This is easy to see: since $V$ is prefix closed, the set of all prefixes of $s$ is a subset of $V$, and so it satisfies the alternating condition with respect to $\zeta_{A\tensor B}$.  
  \end{proof}
\end{proposition}

A design feature of the connectives $\tensor,\parr,\implies$ is that only player $O$ may switch games in $A\tensor B$, while only player $P$ may switch games in $A\parr B$ and $A\implies B$.  The $\implies$ case follows immediately from the $\parr$ case by noting that $A\implies B = \neggame A\parr B$, and the $\parr$ case then follows from the $\tensor$ case by observing that $A\parr B=\neggame{(\neggame A \tensor \neggame B)}$.  Thus, it will suffice to prove the following proposition for the tensor product:

\begin{proposition}
  \label{WhoSwitchesGames}
  Let $A,B$ be games.  Suppose $s\in P_{A\implies B}$, $a\in M_A$ and $b\in M_B$.  Then:

  i) If $sab\in P_{A\tensor B}$ then $\lambda_{A\tensor B}(b)=O$

  ii) If $sba\in P_{A\tensor B}$ then $\lambda_{\tensor B}(a)=O$.  

  \begin{proof}

    (i): $\begin{aligned}[t]
      \lambda_{A\tensor B}(b) & = \zeta_{A\tensor B}(sab) \\
       & = \zeta_{A\tensor B}(s\vert_A a) \wedge \zeta_{A\tensor B}(s\vert_B b) \\
       & = \lambda_{A\tensor B}(a) \wedge \lambda_{A\tensor B}(b)
    \end{aligned}$

    By alternation, either $\lambda_{A\tensor B}(a)=O$ or $\lambda_{A\tensor B}(b)=O$, so this last expression must be equal to $O$.
    
    (ii): \noindent$\begin{aligned}[t]
      \lambda_{A\tensor B}(a) & = \zeta_{A\tensor B}(sba) \\
       & = \zeta_{A\tensor B}(s\vert_A a) \wedge \zeta_{A\tensor B}(s\vert_B b) \\
       & = \lambda_{A\tensor B}(a) \wedge \lambda_{A\tensor B}(b) = O\textrm{ (by the same argument)} && \quad\;\qedhere
    \end{aligned}$
  \end{proof}
\end{proposition}

\subsection{A category of games and partial strategies}
\label{CategoricalSemantics}

Following \cite{joyalgames} and \cite{abramskyjagadeesangames}, we define a category $\G$ whose objects are games where the morphisms from a game $A$ to a game $B$ are strategies for $A\implies B$.  For the sake of simplicity, and to avoid varioius technical issues, we shall require that the games in our category be \emph{negative} - namely, they should start with an opponent move.  In our language, we call a game $A$ \emph{negative} if $\zeta_A(\emptyplay)=P$ (and we call it positive if $\zeta_A(\emptyplay)=O$).  The equations
\begin{gather*}
  P \wedge P = P \\
  P \Rightarrow P = P
\end{gather*}
tell us that the class of negative games is closed under $\tensor$ and $\implies$ (since $P\vee P=P$, it is also closed under $\parr$, but the par of two negative games has no legal moves in our presentation, so it does not give a good model of the $\parr$ connective in linear logic and we will not consider it).

In order to get a category, we need a way to compose a strategy for $A\implies B$ with a strategy for $B\implies C$.  Our treatment of composition is heavily influenced by work done by Hyland and Schalk (see \cite{hyland1997games} and \cite{hylandschalkgames}).  

We shall use the usual definition of composition.  If $\sigma$ is a strategy for $A\implies B$ and $\tau$ is a strategy for $B\implies C$, we define a set
\[
  \sigma\|\tau = \{\s\in (M_A \cprd M_B \cprd M_C)^*\suchthat \s\vert_{A,B}\in\sigma,\;\s\vert_{B,C}\in\tau\}
  \]
Then we define the composite strategy on $A\implies C$ to be
\[
  \comp\tau\sigma = \{\s\vert_{A,C}\suchthat\s\in\sigma\|\tau\}
  \]
The process of showing that this is indeed a strategy for $A\implies C$, and that composition is associative, will be quite involved.  We shall start by recording some nice properties of negative games that will tell us that $\comp\tau\sigma$ is alternating:

\begin{proposition}
  Let $A,B$ be negative games and suppose that $s\in P_A\|P_B$ is alternating with respect to $\zeta_{A\tensor B}$.  Then:
  \begin{enumerate}[i)]
    \item Either $\zeta_{A}(s\vert_A)=P$ or $\zeta_{B}(s\vert_B)=P$.  
    \item $s$ is well formed with respect to $\zeta_{A\tensor B},\lambda_{A\tensor B}$.  
  \end{enumerate}
  Furthermore, (i) and (ii) hold if we replace $\tensor$ with $\implies$ throughout and if we replace (i) by the statement that either $\zeta_A(s\vert_A)=P$ or $\zeta_B(s\vert_B)=O$.
  \label{nice-negative-games}
\end{proposition}

We gave an example earlier in which a play $sa$ in $P_A\|P_B$ was not well formed with respect to $\zeta_{A\tensor B},\lambda_{A\tensor B}$.  The crucial thing that made that example work was that we had $\zeta_A(s\vert_A)=\zeta_B(s\vert_B)=O$.  This then meant that $\zeta_{A\tensor B}(sa)=O$ even when $\lambda_{A\tensor B}=P$.  Part (i) of the proposition above tells us that this situation never occurs, and part (ii) tells us that this is enough to ensure that we never get any alternating sequences that are not well formed.

\begin{proof}[Proof of Proposition \ref{nice-negative-games}]
  We proceed by induction on the length $n$ of $s$.  If $n=0$ then $s=\emptyplay$ and so $\zeta_A(s\vert_A)=\zeta_A(\emptyplay)=P$ and similarly for $B$, since $A,B$ are negative games.  Now suppose that $n>0$ - so $s=tm$ for some $t\in P_{A\tensor B},m\in M_{A\tensor B}$.  By induction, either $t\vert_A=P$ or $t\vert_B=P$, so there are three cases:
  \begin{description}
    \item[Case 1:] $\zeta_A(t\vert_A)=P$ and $\zeta_B(t\vert_B)=P$. Then either $tm\vert_A=t\vert_A$ (if $m$ is a $B$-move) or $tm\vert_B=t\vert_B$ (if $m$ is an $A$-move).  This proves part (i).  For part (ii), note that in this case we have $\zeta_{A\tensor B}(t)=P$, so $\zeta_{A\tensor B}(tm)=O$, since $tm$ is alternating.  If $m$ is an $A$-move, it means that $\zeta_B(tm\vert_B)=\zeta_B(t\vert_B)$, so we must have $\zeta_A(tm\vert_A)=O$.  Then
      \[
        \lambda_{A\tensor B}(m)=\lambda_A(m)=\zeta_A(t\vert_Am)=O=\zeta_{A\tensor B}(tm)
        \]
      If $m$ is a $B$-move, the argument is similar.
    \item[Case 2:] $\zeta_A(t\vert_A)=P$ and $\zeta_B(t\vert_B)=O$.  For part (i), it will suffice to show that $m$ is a $B$-move - so $tm\vert_A=t\vert_A$.  Indeed, we have $\zeta_{A\tensor B}(t)=O$, so $\zeta_{A\tensor B}(tm)=P$, since $tm$ is alternating with respect to $\zeta_{A\tensor B}$.  In particular, $\zeta_B(tm\vert_B)=P$, so we must have $tm\vert_B\ne t\vert_B$ and therefore $m$ is a $B$-move.  For part (ii), we have:
      \begin{gather*}
        \lambda_{A\tensor B}(m)=\lambda_B(m)=\zeta_B(t\vert_Bm)=\neg\zeta_B(t\vert_B)=\neg O = P \\
        \zeta_{A\tensor B}(tm)=\neg\zeta_{A\tensor B}(t)=t = \neg O = P = \lambda_{A\tensor B}
      \end{gather*}
    \item[Case 3:] $\zeta_A(t\vert_A)=O$ and $\zeta_B(t\vert_B)=P$.  Similar to Case 2.
  \end{description}

  Finally, note that the $\tensor$ result implies the $\implies$ result after writing $A\implies B=\neggame{A}\parr B = \neggame{(A\tensor \neggame{B})}$.
\end{proof}

A corollary of our result is that we have:
\begin{align*}
  P_{A\tensor B} & = \{s\in P_A\|P_B\suchthat \textrm{$s$ is alternating with respect to $\zeta_{A\tensor B}$}\} \\
  P_{A\implies B} & = \{s\in P_A\|P_B\suchthat \textrm{$s$ is alternating with respect to $\zeta_{A\implies B}$}\}
\end{align*}
if $A,B$ are negative games.  In other words, we can ignore the well-formedness condition on plays if we are dealing with only negative games.

This proposition allows us to prove the following useful fact:

\begin{lemma}
  \label{alternatingsequenceslemma}
  Let $A,B,C$ be negative games, and let $\s\in (M_A\cprd M_B\cprd M_C)^*$.  If any two of the following statements are true, then so is the third:
  \begin{gather*}
    \s\vert_{A,B}\in P_{A\implies B}\\
    \s\vert_{A,C}\in P_{A\implies C}\\
    \s\vert_{B,C}\in P_{B\implies C}
  \end{gather*}
  \begin{proof}
    By symmetry, it will suffice to prove that if $\s\vert_{A,B}\in P_{A\implies B}$ and $\s\vert_{B,C}\in P_{B\implies C}$ then $\s\vert_{A,C}\in P_{A\implies C}$.  If $X,Y$ are negative games, then sequences $t\in P_{X\implies Y}$ are specified by the following properties - $t\vert_X\in P_X$, $t\vert_Y\in P_Y$, if $t$ has even length, then $\zeta_{X\implies Y}(t)=P$ and if $t$ has odd length then $\zeta_{X\implies Y}(t)=O$.  We need to show that these properties holds if $X=A$, $Y=C$ and $t=\s\vert_{A,C}$.  

    Certainly, $\s\vert_{A,C}\vert_A=\s\vert_A=\s\vert_{A,B}\vert_A\in P_A$ and similarly $\s\vert_{A,C}\vert_C\in P_C$.  

    If $\s\vert_{A,C}$ has even length, it means that the lengths of $\s\vert_A$ and $\s\vert_C$ have the same parity, and therefore that the lengths of $\s\vert_{A,B}$ and $\s\vert_{B,C}$ have the same parity.  Since $\s\vert_{A,B}\in\sigma$ and $\s\vert_{B,C}\in\tau$, it follows that $\zeta_{A\implies B}(\s\vert_{A,B})=\zeta_{B\implies C}(\s\vert_{B,C})$.  If $\zeta_B(\s\vert_B)=P$ then $\zeta_{A\implies B}(\s\vert_{A,B})=P$ and if $\zeta_B(\s\vert_B)=O$ then $\zeta_{B\implies C}(\s\vert_{B,C})=P$, so we must have $\zeta_{A\implies B}(\s\vert_{A,B})=\zeta_{B\implies C}(\s\vert_{B,C})=P$.  By transitivity of $\Rightarrow$, it follows that $\zeta_{A\implies C}(\s\vert_{A,C})=P$.  

    If $\s\vert_{A,C}$ has odd length, it means that the lengths of $\s\vert_A$ and $\s\vert_C$ has opposite parities and therefore that the lengths of $\s\vert_{A,B}$ and $\s\vert_{B,C}$ have opposite parities.  So it follows that $\zeta_{A\implies B}(\s\vert_{A,B})=\neg\zeta_{B\implies C}(\s\vert_{B,C})$.  Suppose that $\zeta_{A\implies B}(\s\vert_{A,B})=O$.  Then $\zeta_A(\s\vert_A)=P$ and $\zeta_B(\s\vert_B)=O$.  By Proposition \ref{nice-negative-games} above applied to $\s\vert_{B,C}$, we must have $\zeta_C(\s\vert_C)=O$ and therefore $\zeta_{A\implies C}(\s\vert_{A,C})=(P\Rightarrow O)=O$.  

    If instead we have $\zeta_{B\implies C}(\s\vert_{B,C})=O$, then $\zeta_B(\s\vert_B)=P$ and $\zeta_C(\s\vert_C)=O$.  By Proposition \ref{nice-negative-games} applied to $\s\vert_{A,B}$, we must have $\zeta_A(\s\vert_A)=P$ and so $\zeta_{A\implies C}(\s\vert_{A,C})=(P\Rightarrow O) = O$.  
  \end{proof}
\end{lemma}

Now we can move on to the main work.  We start with a surprising lemma about strategies on the implication $A\implies B$.  

\begin{lemma}
  \label{PlayInStrategyDeterminedByComponents}
  et $A,B$ be games and let $\sigma$ be a strategy for $A\implies B$.  Suppose that $s,t\in\sigma$ are such that $s\vert_A=t\vert_A$ and $s\vert_B=t\vert_B$.  Then $s=t$.
  \begin{proof}
    Suppose that $s\ne t$.  Let $r\prefix s,t$ be the longest common subsequence of $s$ and $t$ - so we have $rx\prefix s, ry\prefix t$ for some moves $x,y\in M_{A\implies B}$ with $x\ne y$.  Since $rx,ry$ are both substrings of the strategy $\sigma$, $r$ must be a $P$-position and therefore the moves $x,y$ must take place in the same game.  Without loss of generality, suppose that $x,y\in M_A$.  Then we have $r\vert_Ax\prefix s\vert_A,r\vert_Ay\prefix t\vert_A$ and so $s\vert_A\ne t\vert_A$.
  \end{proof}
\end{lemma}

Thus we see that the plays according to some given strategy $\sigma$ for $A\implies B$ are characterized by their $A$- and $B$-components.  More is true, however: given negative games $A$ and $B$, the strategies on $A\implies B$ are characterized by the $A$- and $B$-components of their constituent plays:
\begin{lemma}
  \label{HylandSchalkFaithful}
  Let $A,B$ be negative games and let $\sigma,\sigma'$ be strategies for $A\implies B$ such that
  \[
    \{(s\vert_A,s\vert_B)\suchthat \textrm{$s\in\sigma$ is a $P$-position}\}=\{(s'\vert_A,s'\vert_B)\suchthat\textrm{$s'\in\sigma'$ is a $P$-position}\}
    \]
  Then $\sigma=\sigma'$.
  \begin{proof}
    Suppose for a contradiction that $\sigma\ne\sigma'$, so without loss of generality there is some $P$-position $s\in\sigma\setminus\sigma'$ (using the definition of a strategy).  By hypothesis, there is some $s'\in\sigma'$ such that $s'\vert_A=s\vert_A$ and $s'\vert_B=s\vert_B$.  Clearly, $s\ne s'$, since $s\ne\sigma'$, so let $r\prefix s$ be the largest common prefix of $s$ and $s'$.  We therefore have $rx\prefix s,ry\prefix s'$, where $x,y\in M_{A\implies B}$ and $x\ne y$.  

    Since $s\not\in\sigma'$, $rx\not\in\sigma'$.  Since $ry\in\sigma'$, $x$ and $y$ must be $P$-moves by the definition of a strategy.  Suppose without loss of generality that $x\in M_A$.  Then $y$ cannot also be an $A$-move, or we would have $r\vert_Ax\prefix s\vert_A$ and $r\vert_Ay\prefix s'\vert_A=s\vert_A$, which would contradict the fact that $x\ne y$.  So $y\in M_B$.  Now, by hypothesis, there exists some $P$-position $t\in\sigma$ such that $t\vert_A=ry\vert_A=r\vert_A$ and $t\vert_B=ry\vert_B=r\vert_By$.

    Now clearly $rx\ne t$ (since their restrictions to $A$ and $B$ are different).  Let $q\prefix rx, t$ be their largest common prefix; then we have $qu\prefix rx, qv\prefix t$ for some $u\ne v$.  But now since $qu, qv\in\sigma$, $u$ and $v$ must both be $O$-moves, so they must be contained in the same component.  But this is impossible: if they are both $A$-moves then we have $q\vert_Au\prefix r\vert_Ax$ and $q\vert_Av\prefix r\vert_A$, so $u=v$ and if they are both $B$-moves then we have $q\vert_Bu\prefix r\vert_B$ and $q\vert_Bv\prefix r\vert_By$, so $u=v$ again.  This is a contradiction.
  \end{proof}
\end{lemma}

Given games $A,B$ and a strategy $\sigma$ for $A\implies B$, the set
\[
  \{(s\vert_A,s\vert_B)\suchthat \textrm{$s\in\sigma$ is a $P$-position}\}\subset P_A\times P_B
  \]
is a \emph{relation} between $P_A$ and $P_B$.  Writing $\grel\sigma\subset P_A\times P_B$, we will show that if $A,B,C$ are games and $A\xrightarrow{\sigma}\map{\tau}{B}{C}$ are morphisms, then:
\[
  \grel{\comp\tau\sigma}=\comp{\grel\tau}{\grel\sigma}
  \]
under the usual composition of relations:
\[
  \comp{\grel\tau}{\grel\sigma} = \{(s,t)\in P_A\times P_C\suchthat \exists u\in P_B\esuchthat (s,u)\in\grel\sigma,\;(u,t)\in\grel\tau\}
  \]
Thus we will get a functor $\cmap{\F}{\G}{\Rel}$, where $\G$ is our category of negative games and $\Rel$ is the category of sets and relations.  Proposition \ref{HylandSchalkFaithful} then tells us that this functor is faithful.  

It is clear from the definition of $\comp\tau\sigma$ that $\grel{\comp\tau\sigma}\subset\comp{\grel\tau}{\grel\sigma}$; indeed if $\s\in\sigma\|\tau$, then $(\s\vert_A,\s\vert_B)\in\grel\sigma$ and $(\s\vert_B,\s\vert_C)\in\grel\tau$, so $(\s\vert_A,\s\vert_C)\in\comp{\grel\tau}{\grel\sigma}$.  To show the reverse inclusion, we need to show the following: if $s\in\sigma$ and $t\in\tau$ are such that $s\vert_B=t\vert_B$, then there is some $\s\in (M_A\cprd M_B\cprd M_C)^*$ such that $\s\vert_{A,B}=s$ and $\s\vert_{B,C}=t$.  

This can be shown in an easy way.  Roughly speaking, we write out the sequence $s$, and then insert immediately after each $B$-move the $C$-moves from $t$ that occur after that $B$-move.  This technique works for arbitrary sequences and is sufficient to prove that $\grel{\comp\tau\sigma}=\comp{\grel\tau}{\grel\sigma}$.  However, it turns out that if $s$ and $t$ are alternating plays in $A\implies B$ and $B\implies C$ then this interleaving is unique - and even more is true:

\begin{lemma}
  \label{LiftingLemma}
  Let $A,B,C$ be negative games, let $\sigma$ be a strategy for $A\implies B$ and let $\tau$ be a strategy for $B\implies C$.  Suppose that $s\in\sigma$ and $t\in\tau$ are such that $s\vert_B=t\vert_B$.  Let $n=\length(s)+\length(t\vert_C)$; i.e., the total number of unique terms of $s$ and $t$ after we have identified their unique $B$-component.  Then for all $k$ with $0\le k\le n$, there is a unique sequence $\s^k\in\sigma\|\tau$ of length $k$ such that $\s^k\vert_A\prefix s\vert_A$ and $\s^k\vert_C\prefix t\vert_C$.  Moreover, for this $\s^k$ we have $\s^k\vert_{A,B}\prefix s$ and $\s^k\vert_{B,C}\prefix t$, and if $j\le k$ then $\s^j\prefix \s^k$.  
\end{lemma}

Note that Lemma \ref{LiftingLemma} is stronger than saying that there is a unique sequence $\s^k$ of length $k$ such that $\s^k\vert_{A,B}\prefix s$ and $\s^k\vert_{B,C}\prefix t$.  Instead, we are saying that there exists a sequence $\s^k$ with those properties, but that it is uniquely determined even when we make no requirement on its $B$-component other than that the whole sequence is contained in $\sigma\|\tau$.

As a corollary, we see that the sequences $s$ and $t$ may be interleaved: set $\s=\s^n$; then we have $\s\vert_{A,B}\prefix s$ and $\s\vert_{B,C}\prefix t$.  In fact, we have $\s\vert_{A,B}=s$ and $\s\vert_{B,C}=t$ by a length argument:
\[
  \length(\s\vert_{A,B})\le\length(s)=n-\length(t\vert_C)\le n-\length(\s\vert_C)=\length(\s\vert_{A,B})
  \]
so we must have equality everywhere, and similarly for $\s\vert_{B,C}$ and $t$.

\begin{proof}[Proof of Lemma \ref{LiftingLemma}]
  We prove this by induction on $k$.  There is a unique sequence of length $0$, namely the empty sequence, and its $A$- and $C$-components are both empty, so are prefixes of $s$ and $t$.  

  Suppose now that $k=1$.  We make the observation that if $a$ is an $O$-move in $A$ and if $b$ is an $O$-move in $B$ then $a$ is a $P$-move in $A\implies B$ and $b$ is a $P$-move in $B\implies C$.  Since the starting move in $A\implies B$ or $B\implies C$ must be an $O$-move in both its component game and in the game as a whole, we see that any sequence in $\sigma\|\tau$ must begin with a move in $C$.  So we have $\s^1=c$, for some $C$-move $c$, and the condition that $\s^1\vert_C\prefix t$ means that $c$ must be the first move in $t$, which is always a move from $C$.  We have $\s^1\vert_A=\emptyplay\prefix s\vert_A$ and $\s^1\vert_B=\emptyplay\prefix s\vert_B$, as desired.

  Now suppose that we have constructed the sequence $\s^k$ for some $k$ such that $1\le k<n$.  We seek a sequence $\s^{k+1}\in \sigma\|\tau$ of length $k+1$ such that $\s^{k+1}\vert_A\prefix s$ and $\s^{k+1}\vert_C\prefix t$.  If we write $\s'$ for the sequence obtained by removing the last move in $\s^{k+1}$, it is clear that $\s'\vert_A\prefix s$ and $\s'\vert_C\prefix t$, so $\s'=\s^k$ by uniqueness.  Therefore, $\s^{k+1}$ is of the form $\s^kx$, for some move $x\in M_A\cprd M_B\cprd M_C$.  

  Write $\s^k=\s''y$, where $y$ is the last move in $\s^k$.  Our move $x$ will depend on which game $y$ is played on as follows:
  
  \begin{itemize}
    \item Suppose $y$ is a move in $A$ or an $O$-move in $B$.  By induction, $\s''y\vert_{A,B}$ is a prefix of $s$ ending in $y$.  We claim that it is a proper prefix.  

      Indeed, let $b$ be the last $B$-move occurring in $\s''y$ (since play in $A\implies B$ starts with a $B$-move, there must be such a move).  If $b=y$, then $b$ is an $O$-move in $A\implies B$.  Otherwise, $y$ must be a move in $A$, and then $b$ is again an $O$-move in $A\implies B$, since player $P$ switches games.  Therefore, $b$ is a $P$-move in $B\implies C$.  Now $\s''y\vert_B$ is a prefix of $t$ ending in $b$.  Since $b$ is a $P$-move in $B\implies C$, it may only be followed in $B\implies C$ by another move from $B$, so there are two possibilities: either $\s''y\vert_{B,C}=t$ or there is some other $B$-move $b'$ that occurs later than $b$ in the sequence $t$.  In the first case, $\s''y\vert_{A,B}$ must be a proper prefix of $s$ by length considerations:
      \begin{align*}
        \length(\s''y\vert_{A,B}) & = \length(\s''y) - \length(\s''y\vert_C) \\
          & = \length(\s''y) - \length(t\vert_C) \\
          & = k - \length(t\vert_C) < n - \length(t\vert_C) = \length(s)
      \end{align*}
      while in the second case $\s''y\vert_B$ must be a proper prefix of $t\vert_B=s\vert_B$, and so $\s''y\vert_{A,B}$ must be a proper prefix of $s$.

      Therefore, we have $\s''y\vert_{A,B}x\prefix s$ for some move $x\in M_A\cprd M_B$.  If $x$ is an $A$-move then $\s''yx\vert_{B,C}=\s''y\vert_{B,C}\prefix t$, as desired.  If $x$ is a move in $B$, then it must be a $P$-move in $A\implies B$ (since $y$ is either a move in $A$ or an $O$-move in $B$), so it is an $O$-move in $B\implies C$.  Since $s\vert_B=t\vert_B$, we must have $\s''yx\vert_B\prefix t\vert_B$, and so $y$ must be a $P$-move in $B\implies C$, and should therefore be followed by another move in $B$, which must be $x$.  Therefore, $\s''yx\vert_{B,C}\prefix t$.

      For uniqueness, suppose that $\s''yz\in\sigma\|\tau$ is such that $\s''yz\vert_A\prefix s\vert_A$ and $\s''yz\vert_C\prefix t\vert_C$.  As before, let $b$ be the last $B$-move occurring in $\s''y$; we have already shown that $b$ must be a $P$-move in $B\implies C$, and it follows that it must be the last move occurring in $\s''y\vert_{B,C}$ (since it can only be followed by another $B$-move).  Suppose that $z\in M_B\cprd M_C$.  Then $\s''yz\vert_{B,C}=\s''y\vert_{B,C}z$; since the last move in $\s''y\vert_{B,C}$ is $b$, this means that $z$ must be an $O$-move in $B$.  So $z$ is either an $O$-move in $B$ or a move in $A$.

      If $y$ was an $O$-move in $A$, then $y$ is a $P$-move in $A\implies B$, so it must be followed in $A\implies B$ by another move from $A$.  Then the condition that $\s''yz\vert_A\prefix s\vert_A$ tells us that $z=x$.  If instead $y$ was a $P$-move in $A$ or a move in $B$ then $y$ is an $O$-move in $A\implies B$; now, since we have $\s''y\vert_{A,B}z,\s''y\vert_{A,B}x\in\sigma$, it must be the case that $x=z$ by the definition of a strategy.

    \item If instead $y$ is a move in $C$ or a $P$-move in $B$, we use a symmetrical argument, choosing $x$ to be the next move along in $t$.  We need to take a little extra care here when we talk about the last $B$-move in $\s''y$; there may in fact be no $B$-moves in $\s''y$.  Since any play in $A\implies B$ must begin with a $B$-move, this only happens when $\s''y$ is entirely made up of $C$-moves.  In this case, it is not difficult to show that $\s''y\vert_{B,C}$ is a proper prefix of $t$ by length considerations.  \qedhere
  \end{itemize}
\end{proof}

We now have all the ingredients ready to prove that $\comp\tau\sigma$ is a well-defined strategy.

\begin{proposition}
  Let $A,B,C$ be games, let $\sigma$ be a strategy for $A\implies B$ and let $\tau$ be a strategy for $B\implies C$.  Then $\comp\tau\sigma$ (as defined above) is a strategy for $A\implies C$.  

  \begin{proof}
    By Lemma \ref{alternatingsequenceslemma}, $\comp\tau\sigma\in P_{A\implies C}$.  Moreover, it is non-empty, since it contains $\emptyplay$.  We need to show that the two strategy conditions hold for $\comp\tau\sigma$.  

    Firstly, suppose that $\s\in\sigma\|\tau$ and $\s\vert_{A,C}$ is a $P$-play in $A\implies C$.  Suppose that $\s\vert_{A,C} a\in P_{A\implies C}$ for some $a\in M_A$.  We claim that $\s a\in\sigma\|\tau$.  

    Indeed, certainly $\s a\vert_{B,C}=\s\vert_{B,C}\in\tau$.  Moreover, we have $\s a\vert_{A,C}\in P_{A\implies C}$, so Lemma \ref{alternatingsequenceslemma} tells us that $\s a\vert_{A,B}\in P_{A\implies B}$.  

    Since $a$ is an $O$-move in $A\implies B$, it is an $O$-move in $A\implies C$.  Since $\s\vert_{A,B}\in\sigma$, we must have $\s a\vert_{A,B}\in\sigma$, by the definition of a strategy.  So $\s a\in\sigma\|\tau$.  

    By a symmetrical argument, if $\s\vert_{A,C} c\in P_{A\implies C}$ for some $c\in M_C$, then $\s c\in\sigma\|\tau$.  

    For the second strategy property, suppose that $s\in\comp\tau\sigma$ is n $O$-play and that $sx, sy\in\comp\tau\sigma$.  We claim that $x=y$.  By the definition of $\comp\tau\sigma$, there must be sequences $\s,\t\in\sigma\|\tau$ with $\s\vert_{A,C}=sx$ and $\t\vert_{A,C}=sy$.  Moreover, by removing any $B$-moves form the end of $\s,\t$, we may assume that the last move in $\s$ is $x$ and the last move in $\t$ is $y$.  We may write $\s=\s'\b x$ and $\t=\t'\bbeta y$, where $\b$ and $\bbeta$ are sequences composed entirely out of $B$-moves and neither $\s'$ nor $\t'$ ends with a $B$-move.  In particular, $\s'\vert_{A,C}=\t'\vert_{A,C}=s$.

    Without loss of generality, $\length(\s')\le\length(\t')$.  Let $\t''$ be the prefix of $\t'$ that has the same length as $\s'$, writing $\t'=\t''\r$.

    Now $\s'$ and $\t''$ have the same length, and we have
    \[
      \begin{matrix}
        \s'\vert_A\prefix\s\vert_A & \t''\vert_A\prefix\s\vert_A \\
        \s'\vert_C\prefix\s\vert_C & \t''\vert_C\prefix\s\vert_C
      \end{matrix}
      \]
    so we must have $\s'=\t''$, by uniqueness in Lemma \ref{LiftingLemma}.  Now observe that we have
    \[
      \s'\vert_{A,C}=\t'\vert_{A,C}=\t''\vert_{A,C}\r\vert_{A,C}=\s'\vert_{A,C}\r\vert_{A,C}
      \]
    Since $\t'=\t''\r$ does not end with a $B$-move, $\r\vert_{A,C}$ must be non-empty if $\r$ is non-empty.  Therefore $\r=\emptyplay$, and so $\t'=\t''=\s'$.

    We now claim that $\length(\b)=\length(\bbeta)$.  Indeed, suppose instead that $\length(\b)<\length(\bbeta)$.  Then there would be a prefix $\bbeta'\prefix\bbeta$ of length $\length(\b)+1$.  Then we would have
    \[
      \begin{matrix}
        \s'\b x\vert_A=\s\vert_A & \s'\bbeta'\vert_A=\s'\vert_A\prefix\s\vert_A \\
        \s'\b x\vert_C=\s\vert_C & \s'\bbeta'\vert_C=\s'\vert_C\prefix\s\vert_C
      \end{matrix}
      \]
    and so $\s'\b x=\s'\bbeta'$ by Lemma \ref{LiftingLemma}, which is clearly impossible.  Therefore, $\length(\b)=\length(\bbeta)$.  Now we can apply Lemma \ref{LiftingLemma} in the same way to tell us that $\b=\bbeta$.

    Suppose that $\zeta_B(\s'\b\vert_B)=P$.  Since $\s'\b\in\sigma\|\tau$, this means that $\zeta_A(\s'\b\vert_A)=P$, by Proposition \ref{nice-negative-games}(i).  Therefore, $\zeta_{A\implies B}(\s'\b)=P$, so $x$ and $y$ must both be moves in $C$.  Then we have $\s'\b\vert_{B,C}x,\s'\b\vert_{B,C}y\in\tau$, and so $x=y$ by the definition of a strategy.

    By a symmetrical argument, if $\zeta_B(\s'\b\vert_B)=O$, then $x$ and $y$ must both be moves in $A$.  We then have $\s'\b\vert_{A,B}x,\s'\b\vert_{A,B}y\in\sigma$, so $x=y$.
  \end{proof}
\end{proposition}

Now we are ready to define our category $\G$ of games.  We have defined composition of strategies, so we need to define identity morphisms.  Identity morphisms are given by the copycat strategy, as usual:
\[
  \id_A=\left\{s\in P_{A\implies A}\suchthat\textrm{for all even length $t\prefix s$, $t\vert_\bneggame{A}=t\vert_A$}\right\}
  \]
We can now state our first main result.

\begin{theorem}
  The collection of negative games, with morphisms from $A$ to $B$ given by strategies on $A\implies B$ with the notions of composition and identity given above, forms a category $\G$.  Moreover, there is a faithful functor $\F\from\G\to\Rel$, where $\Rel$ is the category of sets and relations, given by sending a game $A$ to the set of plays $P_A$ and sending a strategy $\sigma\from A\implies B$ to the set
  \[
    \grel{\sigma}=\{(s\vert_A,s\vert_B)\suchthat \textrm{$s\in\sigma$ is a $P$-position}\}\subset P_A\times P_B
    \]
  \begin{proof}
    We shall make much use of the relational content of a strategy.  We first need to show that the identity is indeed an identity and that composition is associative.  For the identity, note that $\grel{\id_A}=\Delta_{P_A}\subset P_A\times P_A$, the identity relation in $\Rel$.  If $B,C$ are negative games and $\sigma\colon B\implies A,\tau\colon A\implies C$ are strategies, then from our earlier discussion we have
    \[
      \grel{\comp{\id_A}{\sigma}}=\comp{\grel{\id_A}}{\grel\sigma}=\comp{\Delta_{P_A}}{\grel\sigma}=\grel\sigma
      \]
    and therefore $\comp{\id_A}{\sigma}=\sigma$, by Lemma \ref{HylandSchalkFaithful}.  Similarly, $\comp{\tau}{\id_A}=\tau$.  

    For associativity of composition, we hijack the associativity in $\Rel$: if $A,B,C,D$ are negative games, and $\map{\sigma}AB\xrightarrow{\tau}\map{\upsilon}CD$ are morphisms, then we have:
    \begin{align*}
      \grel{\comp{(\comp\upsilon\tau)}{\sigma}} & = \comp{\grel{\comp\upsilon\tau}}{\sigma} \\
        & = \comp{(\comp{\grel\upsilon}{\grel\tau})}{\grel\sigma} \\
        & = \comp{\grel\upsilon}{(\comp{\grel\tau}{\grel\sigma})} \quad\textrm{by associativity in $\Rel$} \\
        & = \comp{\grel\upsilon}{\grel{\comp\tau\sigma}} \\
        & = \grel{\comp{\upsilon}{(\comp\tau\sigma)}}
    \end{align*}
    and so $\comp{(\comp\upsilon\tau)}{\sigma}=\comp{\upsilon}{(\comp\tau\sigma)}$, by Lemma \ref{HylandSchalkFaithful}.  

    We have already shown that the map $\F$ respects composition, so it is a functor.  It is faithful by Lemma \ref{HylandSchalkFaithful}.
  \end{proof}
\end{theorem}

\subsection{Total strategies and winning conditions}

Let $A$ be a game.  We call a strategy $\sigma$ for $A$ \emph{total} if it satisfies the additional requirement that whenever $s\in\sigma$ is an $O$-play, there exists some $a\in M_A$ such that $sa\in\sigma$ (before we only required that such a play be unique if it existed).  

We might want to talk about a category of negative games and total strategies.  However, we cannot do this immediately, since the composition of two total strategies need not be total.  

\begin{example}
  \label{TotalCompositionExample}
  Let $\st$ be the negative game where each player has a unique move at every position:
  \begin{gather*}
    M_{\st} = \{q,a\} \\
    \lambda_{\st}(q) = O,\;\lambda_{\st}(a)=P \\
    P_{\st} = \{\emptyplay, q, qa, qaq, qaqa, \dots\}
  \end{gather*}

  Let $I$ be the negative game with no moves and let $\bot$ be the negative game with a single opponent move and no further play:
  \[
    \begin{matrix}
      M_I=\emptyset & M_\bot = \{*\} \\
      \lambda_I=\emptyset  & \lambda_\bot(*)=O \\
      P_I=\{\emptyplay\} & P_\bot = \{\emptyplay, *\}
    \end{matrix}
    \]

  It is easy to see that if $A$ is a negative game then strategies for $I\implies A$ are the same thing as strategies for $A$ and that strategies for $A\implies\bot$ are the same thing as opponent strategies for $A$.  So we get morphisms $\cmap{\sigma}{I}{\st},\cmap{\tau}{\st}{\bot}$ given by the unique player and opponent strategies for $\st$:
  \[
    \sigma = P_\st\quad\tau = \{*s\suchthat s\in P_\st\}
    \]
  Moreover, both these strategies are total.

  The plays in $\sigma\|\tau$ are now those sequences $\s\in(M_I\cprd M_\st\cprd M_\bot)^*$ such that:
  \begin{gather*}
    \s\vert_A=\emptyplay \\
    \s\vert_B\in P_\st \\
    \textrm{If $\s\ne\emptyplay$ then $\s\vert_C=*$}
  \end{gather*}

  Upon restricting these sequences to $A$ and $C$, we see that $\comp\tau\sigma$ contains only two plays - $\emptyplay$ and $*$.  $*$ is an $O$-play with no $P$-reply in $\comp\tau\sigma$, so $\comp\tau\sigma$ is not a total strategy.
\end{example}

Clearly it is the infinite play in the game $\st$ that is causing the problem.  We can get around this by insisting that our games contain no infinite plays: if $A$ is a game, we say $A$ has an infinite play if $(P_A,\prefix)$ has an infinite chain.

\begin{proposition}
  \label{BoundedTotalComposition}
  Let $A,B,C$ be negative games and assume that $B$ has no infinite play.  Let $\sigma$ be a total strategy for $A\implies B$ and let $\tau$ be a total strategy for $B\implies C$.  Then $\comp\tau\sigma$ is a total strategy for $A\implies C$.
  \begin{proof}
    We have already shown that $\comp\tau\sigma$ is a strategy for $A\implies C$, so we need to show that it is total.  Let $s\in\comp\tau\sigma$ be an $O$-play.  We seek a $P$-move $x$ such that $sx\in\comp\tau\sigma$.  

    By the definition of $\comp\tau\sigma$, there is some $\s\in\sigma\|\tau$ such that $\s\vert_{A,C}=s$.  Since $P_B$ contains no infinite chain, we may take $\s$ to be maximal such that $\s\vert_{A,B}=s$.  
    
    Since $s$ is an $O$-play, $\s\vert_A$ must be a $P$-play in $A$ and $\s\vert_C$ must be an $O$-play in $C$.  Consider the $B$-component $\s\vert_B$ of $\s$.  If this is an $O$-play, then $\s\vert_{A,B}$ is an $O$-play in $\sigma$, so, by totality of $\sigma$, there exists $x$ such that $\s\vert_{A,B}x\in\sigma$ and therefore $\s x\in\sigma\|\tau$.  Similarly, if $\s\vert_B$ is a $P$-play, then $\s\vert_{B,C}$ is an $O$-play in $\tau$, so there exists $x$ such that $\s\vert_{B,C}x\in\tau$ and so $\s x\in\sigma\|\tau$.  

    If $x$ is a $B$-move, we have $\s x\vert_{A,C}=s$, contradicting maximality of $s$.  Therefore, $x$ is an $A$- or $C$-move, and we have $sx\in\comp\tau\sigma$.
  \end{proof}
\end{proposition}

The result of this proposition means that we could create a category of games and total strategies by requiring that all our games have no infinite plays.  However, the resulting category is too weak for our requirements; in particular, it makes it very difficult to model the exponential from linear logic.  Moreover, it seems a bit wasteful to require that none of the games $A,BC$ have winning plays when it is only winning plays in game $B$ that are causing problems.  

Fortunately, there is a cleverer way of getting around the problem.  Recall that we defined a game to be given by a tuple $(M_A,\lambda_A,\zeta_A,P_A)$.  Given such a game, and given some subset $X\subset P_A$, define $X^\omega$ to be the set of all infinite plays in the game -- i.e., the set of all infinite sequences $s\in M_A^\omega$ all of whose prefixes lie in $X$.  

\begin{definition}
  A \emph{win-game} is a tuple $A=(M_A,\lambda_A,\zeta_A,P_A,W_A)$ where $(M_A,\lambda_A,\zeta_A,P_A)$ is a game as defined before and $\cmap{W_A}{P_A^\omega}{\OP}$ is a function telling us whether each infinite play is a win for player $P$ or for player $O$.  
\end{definition}

To distinguish our original games from these win-games, we shall refer to the earlier games as \emph{finitary games}.  

We can define an appropriate notion of strategies for these games.  If $A$ is a win-game, then a \emph{winning strategy} for $A$ is a total strategy for $(M_A,\lambda_A,\zeta_A,P_A)$ such that $W_A(s)=P$ for all $s\in\sigma^\omega$.  

We can also extend our connectives to our new win games.  At the level of finitary games, our definitions of the connectives are unchanged, and it remains to define the $W$-functions.  If $A$ is a win game, then $W_{\neggame A}=\neg\circ W_A$.  

If $A$ and $B$ are win games, we would like to define $W_{A\tensor B}$ by
\[
  W_{A\tensor B}(s) = W_A(s\vert_A) \wedge W_B(s\vert_B)
  \]
However, this is not well defined at present because one out of $s\vert_A$ and $s\vert_B$ might be a finite sequence even if $s$ is infinite.  For this purpose, it will be convenient to extend our function $W_A$ to include finite plays as well using $\zeta_A$:
\[
  W_A^* = \zeta_A\cprd W_A\from P_A\cprd P_A^\omega \to\OP
  \]
We can then define
\[
  W_{A\tensor B}(s) = W_A^*(s\vert_A)\wedge W_B^*(s\vert_B)
  \]
Indeed, we could do away with $\zeta_A$ and $W_A$ altogether, replacing them with $W_A^*$.  Since the rule for $\zeta_{A\tensor B}$ is also given by a conjunction, our rule for the tensor product becomes:
\[
  W_{A\tensor B}^*(s) = W_A^*(s\vert_A)\wedge W_B^*(s\vert_B)
  \]
This will be the starting point for our development of transfinite games in the next section.  In our formulation, finitary games are games played over the ordinal $\omega$, while win-games will be games played over the ordinal $\omega+1$.  We make no special distinction between finite and infinite plays, so the function $\zeta_A$ for our transfinite games incorporates both the function $\zeta_A$ and the function $W_A$ from our win-games, in the same manner as the function $W_A^*$ defined above.  One advantage of this point of view is that we no longer have to treat the finite- and infinite-play cases separately, but can give a uniform presentation.  

For now, let us concentrate on developing the theory of win-games in the traditional way.  Having defined the tensor product, we may recover the definitions of the par $\parr$ and linear implication $\implies$ of two games as usual.  In particular, this means that we have
\[
  W_{A\implies B}^*(s) = (W_A(s\vert_A) \Rightarrow W_B(s\vert_B))
  \]

It is worth examining the definitions of the $W$-functions for tensor and implication.  Recall that in the tensor product, it is always player $O$ who switches games.  Therefore, if $s$ is an infinite play in $A\tensor B$ and $s\vert_A$ is finite and non-empty, it must be the case that player $P$ made the last move in $s$, and so $W_A^*(s\vert_A)=P$.  If we assume our games are negative, then this extends to the case that $s\vert_A$ is empty.  This tells us that player $P$ wins an infinite play $s$ in $A\tensor B$ if and only if each component is either $P$-winning or is finite.  

Similarly, player $P$ wins an infinite play $s$ in $A\implies B$ if and only if $s\vert_A$ is infinite and $O$-winning or if $\s\vert_B$ is either finite or is infinite and $P$-winning.  Since it is player $P$ who switches games in $A\implies B$, if $s\vert_A$ is finite then it will end with an $O$-move, so will count as an $O$-winning play.  

The point now is that if $A,B,C$ are negative win-games and $\sigma$ and $\tau$ are strategies for $A\implies B$ and $B\implies C$, we will never end up in the situation we were in in Example \ref{TotalCompositionExample} where we have an infintie play in $B$ that stops us from replying in the composition $\comp\tau\sigma$.  In that example, the unique infinite play in $\st$ would have to be either $O$-winning or $P$-winning, so either $\sigma$ or $\tau$ would not be a valid winning strategy.  

\begin{proposition}
  Let $A,B,C$ be negative win-games, let $\sigma$ be a winning strategy for $A\implies B$ and let $\tau$ be a winning strategy for $B\implies C$.  Then $\comp\tau\sigma$ is a winning strategy for $A\implies C$.  
  \begin{proof}
    First, we want to show that $\comp\tau\sigma$ is a total strategy.  Let $s\in\comp\tau\sigma$ be an $O$-position; then we have some $\s\in\sigma\|\tau$ with $\s\vert_{A,C}=s$.  

    We claim that there is a maximal such $\s$.  By Lemma \ref{LiftingLemma}, $\s$ is determined by its length, and so the only way that there could not be a maximal such $\s$ is if there is some infinite sequence $\S\in(M_A\cprd M_B\cprd M_C)^\omega$ with $\S\vert_{A,B}\in\sigma\cup\sigma^\omega$, $\S\vert_{B,C}\in\tau\cup\tau^\omega$ and $\S\vert_{A,C}=s$.  Since $\S$ has some finite prefix $\s$ with $\s\vert_{A,C}=s$, $\S\vert_A$ and $\S\vert_C$ must both be finite, so they are $O$-plays in the games $A\implies B$ and $B\implies C$ respectively.  

    Now $\S\vert_B$ is infinite.  If $W_B(\S\vert_B)=O$, then $W_{A\implies B}(\S\vert_{A,B})=O$, contradicting the fact that $\sigma$ is a winning strategy.  Symmetrically, if $W_B(\S\vert_B)=P$, then $W_{B\implies C}(\S\vert_{B,C})=O$, contradicting the fact that $\tau$ is a winning strategy.  We have a contradiction in either case, so if $\sigma$ and $\tau$ are indeed winning strategies, there must be a maximal (finite) $\s\in\sigma\|\tau$ such that $\s\vert_{A,C}=s$.  

    The argument from Proposition \ref{BoundedTotalComposition} now applies, showing that $sx\in\comp\tau\sigma$ for some $P$-move $x$.  

    Lastly, we want to show that any infinite play in $\comp\tau\sigma$ is $P$-winning.  Suppose $s$ is some infinite play in $\comp\tau\sigma$.  For each finite prefix $t\prefix s$ there is some $\t\in\sigma\|\tau$ with $\t\vert_{A,C}=t$, and by Lemma \ref{LiftingLemma}, we have $\t'\prefix\t$ if $t'\prefix t$.  Therefore, these $\t$ glue to give an infinite sequence $\s\in(M_A\cprd M_B\cprd M_C)^\omega$ such that $\s\vert_{A,B}\in\sigma^\omega$ and $\s\vert_{B,C}\in\tau^\omega$.  We claim that $W_{A\implies B}^*(\s\vert_{A,B})=W_{B\implies C}^*(\s\vert_{B,C})=P$ - then it follows that $W_{A\implies C}^*(\s\vert_{A,C})=P$ by transitivity of $\Rightarrow$.  If $\s\vert_{A,B}$ and $\s\vert_{B,C}$ are both infinite, then this is automatically true, since $\sigma$ and $\tau$ are winning strategies.  Otherwise, one of them must be infinite and the other finite.  

    Suppose that $\s\vert_{A,B}$ is finite.  Let $\t$ be the shortest finite prefix of $\s$ with $\t\vert_{A,B}=\s\vert_{A,B}$; then we have $\t c\prefix \s$ for some move $c\in M_C$.  If $\t\vert_{A,B}=\emptyplay$, then $W_A^*(\t\vert_{A,B})=P$ since $A$ and $B$ are negative.  Otherwise, there is at least one $B$-move in $\t\vert_{A,B}$.  Let $b$ be the last $B$-move occurring in $\t\vert_{A,B}$ - then it is the last $B$-move occurring in $\t\vert_{B,C}$; since it is followed by the move $c$, it must be an $O$-move in $B\implies C$ and therefore a $P$-move in $B$.  Therefore, $W_{A\implies B}^*(\s\vert_{A,B})=P$.  

    If instead $\s\vert_{B,C}$ is finite, once again we have some $\t\prefix\s$ with $\t\vert_{A,B}=\s\vert_{A,B}$ and $\t a\prefix\s$ for some move $a\in M_A$.  Since $\s\vert_{A,B}$ is infinite, it must be non-empty, so it must contain some $B$-move.  Let $b$ be the last $B$-move occurring in $\s\vert_{A,B}$; since $b$ is followed by an $A$-move, it must be an $O$-move in $B$.  Now $b$ is also the last $B$-move occurring in $\s\vert_{B,C}$ and so $W_{B\implies C}^*(\s\vert_{B,C})=P$.
  \end{proof}
\end{proposition}

We get another result:

\begin{theorem}
  The collection of all negative win-games, with morphisms from $A$ to $B$ given by winning strategies on $A\implies B$ and composition defined as above, is a category.
  \begin{proof}
    We have shown already that the composition of two winning strategies is a winning strategy.  Associativity of composition is inherited from finitary games and the identity strategy is winning for $A\implies A$.  
  \end{proof}
\end{theorem}

\subsection{Monoidal and sequoidal category structure}

The tensor product $\tensor$ makes $\G$ into a monoidal category.  To show this, we will introduce a few more technical tools.

\subsubsection{Copycat strategies}

We have already introduced the copycat strategy $\id_A$ on a game $A$.  We can extend this idea to more general strategies as follows:

\begin{definition}
  Let $A,B$ be games, and let $\cmap{f}{P_A}{P_B}$ be a bijective function that preserves length and preserves the prefix ordering (i.e., a \emph{tree isomorphism}).  The \emph{copycat strategy} corresponding to $f$ is given by
  \[
    \sigma_f = \left\{s\in P_{A\implies B}\suchthat\textrm{for all even length $t\prefix s$, $t\vert_B=f(t\vert_A)$}\right\}
    \]
\end{definition}

\begin{proposition}
  \begin{enumerate}[i)]
    \item For any tree isomorphism $\cmap{f}{P_A}{P_B}$, $\sigma_f$ is a strategy on $A\implies B$.

    \item If $A,B,C$ are games, $\cmap{f}{P_A}{P_B}$ is a tree isomorphism and $\sigma$ is a strategy for $B\implies C$, then the composition of $\sigma$ and $\sigma_f$ is given by:
      \[
        \comp\sigma{\sigma_f} =
        \]
  \end{enumerate}
\end{proposition}

TODO: come back to this maybe.

\section{Transfinite games}

\begin{note}
  In this section, we assume familiarity with ordinals, ordinal arithmetic and transfinite induction/recursion.  We shall frequently identify an ordinal $\alpha$ with the set $\{\beta\suchthat\beta<\alpha\}$ of all ordinals less than $\alpha$ without comment.
\end{note}

In the last section, we came across win-games, where in addition to the usual function $\cmap{\zeta_A}{P_A}{\OP}$ we have a function $\cmap{W_A}{P_A^\omega}{\OP}$, where $P_A^\omega$ is the set of infinite limits of plays in $P_A$.  We saw that it is usefult to combine these two functions into one:
\[
  W_A^* = \zeta_A\cprd W_A\from P_A\cprd P_A^*\to\OP
  \]
This suggests that it might make sense to combine $P_A$ and $P_A^\omega$ into one a single set $\overline{P_A}$ and use the function $W_A^*$ instead of $\zeta_A$ and $W_A$.  This new set will contain both finite and infinite plays, and the infinite plays will be precisely the limits of the finite plays.  In this way, the set of possible lengths of plays in $\overline{P_A}$ is the set $\{0,1,2,3,\dots,\omega\}$, or the ordinal $\omega+1$.  

Contrast this with the finitary case, in which the set of possible lengths of plays is the set $\{0,1,2,3,\dots\}$, or the ordinal $\omega$.  In the coming sections, we will generalize these results so that we end up with games where the plays can have much larger ordinal lengths.  Win-games will be taken to be the motivating example throughout.  

\subsection{Transfinite Games and Strategies}

We fix some ordinal $\alpha$ throughout.  Given a set $M$, we write $M^{*<\alpha}$ for the set of all ordinal-length sequences of elements of $M$ whose length is less than $\alpha$.  

\begin{definition}
  A \emph{game over $\alpha$}, or an \emph{$\alpha$-game}, is given by a tuple
  \[
    A = (M_A, \lambda_A, \zeta_A, P_A)
    \]
  where
  \begin{itemize}
    \item $M_A$ is a set of moves.
    \item $\cmap{\lambda_A}{M_A}{\OP}$ is a function telling us which player may make each move.
    \item $P_A$ is a set of pairs $(\beta, s)$, where $\beta<\alpha$ is some ordinal and $\cmap{s}{\beta}{M_A}$ is a sequence of moves of length $\beta$.  
    \item $\cmap{\zeta_A}{P_A}{\OP}$ tells us which player owns each position.
  \end{itemize}

  We will normally abuse notation and write $s$ instead of $(\beta, s)$ and $\length(s)$ instead of $\beta$.  If $a\in M_A$, we will write $a$ for the $1$-move play $(1, a)$, and $st$ for the concatenation of two sequences $s$ and $t$ (where $\length(st)=\length(s)+\length(t)$).  We will write $t\prefix s$ if $\length(t)\le\length(s)$ and $s\vert_{\length(t)}=t$.  

  To be called a game, $(M_A, \lambda_A, \zeta_A, P_A)$ has to satisfy four rules.
  \begin{description}
    \item[Prefix closure] $P_A$ must be closed under the relation $\prefix$.  
    \item[Well-formedness] If $a\in M_A$ and $sa\in P_A$ then $\zeta_A(sa)=\lambda_A(a)$.  
    \item[Alternating condition] If $a\in M_A$ and $sa\in P_A$ then $\zeta_A(s)=\neg\zeta_A(sa)$.
    \item[Limit condition] If $\mu<\alpha$ is a limit ordinal and $s\in(M_A)^\mu$ is a sequence of length $\mu$ such that every proper prefix $t\pprefix s$ is in $P_A$, then $s$ is in $P_A$.  
  \end{description}
\end{definition}

\begin{remark}
  In the $\omega+1$ case, the limit condition tells us that the plays of length $\omega$ in $P_A$ are precisely those infinite plays all of whose finite prefixes lie in $P_A$.  It also guarantees that $P_A$ is non-empty, since the empty play $\emptyplay$ will always satisfy the conditions.

  In the $\omega+1$ case, $\zeta_A$ will take the role of what we previously called $W_A^*$, while $P_A$ takes the role of what we called $P_A\cprd P_A^\infty$.  
\end{remark}

We define strategies for these games in much the same way that we defined them before:

\begin{definition}
  Let $A$ be an $\alpha$-game.  A (partial) \emph{strategy} for $A$ is a subset $\sigma\subset P_A$ satisfying three conditions:
  \begin{description}
    \item[$\sigma$ contains all $O$-replies] If $s\in\sigma$ is a $P$-play and $sa\in P_A$ is an $O$-response, then $sa\in\sigma$.
    \item[$P$-replies are unique] If $s\in\sigma$ is an $O$-play and $sa,sb\in\sigma$ are $P$-responses, then $a=b$.
    \item[Limit condition] If $\mu<\alpha$ is a limit ordinal and $s\in P_A$ is a sequence of length $\mu$ such that every proper prefix $t\pprefix s$ lies in $\sigma$, then $s\in\sigma$.
  \end{description}

  We call $\sigma$ \emph{total} if it satisfies the extra requirement:

  \begin{description}
    \item[$P$ always has a reply] If $s\in\sigma$ is an $O$-play, then there is some $P$-move $a\in M_A$ with $sa\in\sigma$.
  \end{description}
\end{definition}

The only new part of this is the limit condition.  Let us examine what it means in the $\omega+1$ case.  Play according to a total strategy $\sigma$ gives rise to a sequence of plays $\emptyplay \prefix s_1\prefix s_2\prefix\dots$ (were $s_i$ has length $i$).  The limit condition then tells us that the limit $s_\omega$ of these plays must be contained in $\sigma$.  If $\zeta_A(s_\omega)=O$ then $P$ has no response to $s_\omega$ (since there are no plays of length $\omega+2$), contradicting totality of $\sigma$.  So for $\sigma$ to be a total strategy, we must have $\zeta_A(s_\omega)=P$ for every $s_\omega$ arising as the limit of finit plays according to $\sigma$.  So total strategies for $\omega+1$-games are exactly the same thing as the winning strategies for win-games that we defined earlier.  

If $s\in P_A$ and $\length(s)$ is a successor ordinal, we will call $s$ a \emph{successor play} or \emph{successor position}.  If $\length(s)$ is a limit ordinal, we will call $s$ a \emph{limiting play} or \emph{limiting position}.

\subsection{Connectives}

We may define connectives for $\alpha$-games in much the same way that we defined them for finitary games and win-games.  

\begin{definition}
  Let $A$ be an $\alpha$-game.  The negation $\neggame A$ of $A$ is given by
  \begin{itemize}
    \item $M_\bneggame A=M_A$
    \item $\lambda_\bneggame A = \neg\circ\lambda_A$
    \item $\zeta_\bneggame A = \neg\circ\zeta_A$
    \item $P_\bneggame A = P_A$
  \end{itemize}
\end{definition}

For the other connectives -- $\tensor$, $\parr$ and $\implies$ -- we will use interleaved plays.  If $A$ and $B$ are $\alpha$ games, then our interleaved plays will be sequences taking values in $M_A\cprd M_B$.  If $\beta<\alpha$ and $s\in(M_A\cprd M_B)^\beta$, we may write $\beta_A$ for $s\inv(M_A)$ and $\beta_B$ for $s\inv(M_B)$.  

\begin{lemma}
  \label{TechnicalOrdinalLemma}
  Let $\beta$ be an ordinal, and let $\gamma$ be any subset of $\beta$.  Then $\gamma$ inherits a well-ordering from $\beta$ and, as ordinals, we have $\gamma\le\beta$.  
  \begin{proof}
    Any subset of $\gamma$ is a subset of $\beta$, so it has a least element.  Therefore, the inherited order on $\gamma$ is a well-order.

    Suppose for a contradiction that $\beta<\gamma$.  Then we have order preserving injections
    \[
      i\from \gamma\hookrightarrow\beta\quad j\from\beta\hookrightarrow\gamma
      \]
    where $i$ is inclusion of $\gamma$ as a subset of $\beta$ and $j$ is inclusion of $\beta$ as a proper initial prefix of $\gamma$.  Let $f\from\gamma\hookrightarrow\gamma$ be the composition $\gamma\xhookrightarrow{i}\beta\xhookrightarrow{j}\gamma$.  Then $f$ is order preserving.  

    Let $S=\{\delta\in\gamma\suchthat f(\delta)<\delta\}$.  $S$ is non-empty, since $\beta\in S$ (considering $\beta$ as an element of $\gamma$), so $S$ has a least element $\xi$.  Now $f(\xi)<\xi$, so $f(f(\xi))<f(\xi)$, since $f$ is order-preserving and injective.  Therefore, $\xi\le f(\xi)$ by minimality of $\xi$, which is a contradiction.
  \end{proof}
\end{lemma}

Using Lemma \ref{TechnicalOrdinalLemma}, we see that $\beta_A,\beta_B\le\beta$; in particular, they are both less than $\alpha$, so we get induced sequences $s\vert_A$ of length $\beta_A$ and $s\vert_B$ of length $\beta_B$.  We define
\[
  P_A\|P_B = \left\{s\in (M_A\cprd M_B)^{*<\alpha}\suchthat s\vert_A\in P_A,\;s\vert_B\in P_B\right\}
  \]

We may now define functions $\zeta_{A\tensor B},\zeta_{A\parr B},\zeta_{A\implies B}\from P_A\|P_B\to\OP$ as before:
\begin{IEEEeqnarray*}{rCc}
  \zeta_{A\tensor B}(s) & = & \zeta_A(s\vert_A)\wedge\zeta_B(s\vert_B)\\
  \zeta_{A\parr B}(s) & = & \zeta_A(s\vert_A)\vee\zeta_B(s\vert_B)\\
  \zeta_{A\implies B}(s) & = & (\zeta_A(s\vert_A)\Rightarrow \zeta_B(s\vert_B))
\end{IEEEeqnarray*}

Our definitions of the functions $\lambda_{A\tensor B},\lambda_{A\parr B},\lambda_{A\implies B}\from M_A\cprd M_B\to \OP$ are the same as before:
\begin{gather*}
  \lambda_{A\tensor B}=\lambda_{A\parr B}=\lambda_A\cprd \lambda_B \\
  \lambda_{A\implies B} = (\neg\circ\lambda_A)\cprd \lambda_B
\end{gather*}

Given a set $M$, a prefix-closed set $P\subset M^{*<\alpha}$ and functions $\cmap{\lambda}{M}{\OP},\cmap{\zeta}{P}{\OP}$, we say that a play $s\in P$ is \emph{well-formed with respect to $\lambda,\zeta$} if whenever $ta\prefix s$ (with $a\in M$) we have $\zeta(ta)=\lambda(a)$.  We say that $s$ is \emph{alternating with respect to $\zeta$} if whenever $t,ta$ are prefixes of $s$ (where $a\in M$), we have $\zeta(t)=\neg\zeta(ta)$.

As before, we now define:

\begin{IEEEeqnarray*}{rCl}
  P_{A\tensor B} & = & \left\{s\in P_A\|P_B \;\middle|\; \mbox{\pbox{\textwidth}{$s$ is alternating with respect to $\zeta_{A\tensor B}$ \\ $s$ is well formed with respect to $\zeta_{A\tensor B},\lambda_{A\tensor B}$}}\right\} \\
  P_{A\parr B} & = & \left\{s\in P_A\|P_B \;\middle|\; \mbox{\pbox{\textwidth}{$s$ is alternating with respect to $\zeta_{A\parr B}$ \\ $s$ is well formed with respect to $\zeta_{A\parr B},\lambda_{A\parr B}$}}\right\} \\
  P_{A\implies B} & = & \left\{s\in P_A\|P_B \;\middle|\; \mbox{\pbox{\textwidth}{$s$ is alternating with respect to $\zeta_{A\implies B}$ \\ $s$ is well formed with respect to $\zeta_{A\implies B},\lambda_{A\implies B}$}}\right\}
\end{IEEEeqnarray*}

Setting $M_{A\tensor B}=M_{A\parr B}=M_{A\implies B} = M_A\cprd M_B$, and restricting $\zeta_{A\tensor B},\zeta_{A\parr B},\zeta_{A\implies B}$ to $P_{A\tensor B},P_{A\parr B},P_{A\implies B}$ respectively, we arrive at our definitions of the connectives:
\begin{IEEEeqnarray*}{cCc}
  A\tensor B & = & (M_{A\tensor B}, \lambda_{A\tensor B}, \zeta_{A\tensor B}, P_{A\tensor B})\\
  A\parr B & = & (M_{A\parr B}, \lambda_{A\parr B}, \zeta_{A\parr B}, P_{A\parr B})\\
  A\implies B & = & (M_{A\implies B}, \lambda_{A\implies B}, \zeta_{A\implies B}, P_{A\implies B})
\end{IEEEeqnarray*}

\begin{proposition}
  $A\tensor B$, $A\parr B$ and $A\implies B$ are well formed games.  Moreover, $P_{A\tensor B}$ is the largest subset $X\subset P_A\|P_B$ such that $(M_{A\tensor B}, \lambda_{A\tensor B}, \zeta_{A\tensor B}, X)$ is a well formed game and similarly for the connectives $\parr$ and $\implies$.
  \begin{proof}
    As before, we prove this proposition for $A\tensor B$ and the other two cases are entirely similar.  Alternatively, observe that $A\parr B=\neggame{(\neggame A \tensor \neggame B)}$ and that $A\implies B = \neggame A \parr B$.  

    Examining the definitions of well formed and alternating sequences, it is immediate that $P_{A\tensor B}$ is prefix-closed.  Moreover, every sequence contained in $P_{A\tensor B}$ is well formed, so the well-formedness condition holds.  If $s,sa\in P_{A\tensor B}$ then $s,sa$ are both prefixes of $sa$ and so we must have $\zeta_{A\tensor B}(s)=\neg\zeta_{A\tensor B}(sa)$, since $sa$ is alternating.  

    To show that the limit condition holds, suppose that $\mu<\alpha$ is a limit ordinal and that $s\in(M_A)^\mu$ is a sequence of length $\mu$ such that $t\in P_{A\tensor B}$ for every proper prefix $t\pprefix s$.  For each $t\pprefix s$, then, we must have $t\vert_A\in P_A$ and $t\vert_B\in P_B$.  

    We claim that $s\vert_A\in P_A$.  Indeed, if $\length(s\vert_A)$ is a successor ordinal, then $s\vert_A$ has a last move $a$.  Let $t$ be the prefix of $s$ consisting of all moves up to and including that last move.  Then $\length(t)$ is a successor ordinal, so $t$ must be a \emph{proper} prefix of $s$, and therefore $s\vert_A=t\vert_A\in P_A$.  If instead $\length(s\vert_A)$ is a limit ordinal, then for every proper prefix $u\pprefix s\vert_A$, we have some $t\prefix s$ with $t\vert_A=u$ (take $t$ to be the prefix consisting of all moves in $s$ that occur in $u$ or that occur before some move in $u$).  Since $s\vert_A\ne u$, $t$ must be a \emph{proper} prefix of $s$, and so $t\vert_A\in P_A$.  Since $u$ is arbitrary, the limit condition for $A$ tells us that $s\vert_A\in P_A$.

    By an identical argument, $s\vert_B\in P_B$, and so $s\in P_A\|P_B$.  We claim that $s$ is alternating with respect to $\zeta_{A\tensor B}$.  Indeed, if $t,ta\prefix s$, then $t,ta$ must both be \emph{proper} prefixes of $s$, since $\length(s)$ is a limit ordinal and $\length(ta)$ is a successor ordinal.  So $ta$ is alternating and therefore $\zeta_{A\tensor B}(t)=\neg\zeta_{A\tensor B}(ta)$.  

    Lastly, we show that $s$ is well formed with respect to $\lambda_{A\tensor B},\zeta_{A\tensor B}$.  Suppose $ta\prefix s$.  Once again, $ta$ must be a \emph{proper} prefix of $s$, since it clearly has a different length.  Therefore, $ta$ is well formed and we have $\zeta_{A\tensor B}(ta)=\lambda_{A\tensor B}(a)$.  Therefore, $s\in P_{A\tensor B}$.  

    For the second part of the proposition, suppose that $V\subset P_A\|P_B$ is prefix closed and satisfies the alternating condition with respect to $\zeta_{A\tensor B}$ and that if $sa\in V$ then $\zeta_{A\tensor B}(sa)=\lambda_{A\tensor B}(a)$.  We want to show that $V\subset P_{A\tensor B}$.  Indeed, if $s\in V$ and $ta\prefix s$, then $ta\in V$ (since $V$ is prefix closed) and therefore $\zeta_{A\tensor B}(ta)=\lambda_{A\tensor B}(a)=\neg\zeta_{A\tensor B}(s)$.  
  \end{proof}
\end{proposition}

As before, we want to show that if player $O$ switches games in the tensor product and that player $P$ switches games in the par and linear implication.  Recalling that if $A,B$ are $\alpha$-games then $A\parr B = \neggame{(\neggame A\tensor \neggame B)}$ and that $A\implies B = \neggame A\parr B$, we only need to prove this for the tensor product:

\begin{proposition}
  \label{TransWhoSwitchesGames}
  Let $A,B$ be $\alpha$-games.  Suppose that $s\in P_{A\implies B}$, $a\in M_A$ and $b\in M_B$.  Then:

  i) If $sab\in P_{A\tensor B}$ then $\lambda_{A\tensor B}(b) = O$

  ii) If $sba\in P_{A\tensor B}$ then $\lambda_{A\tensor B}(a) = O$.

  \begin{proof}
    Unchanged from the finitary case - see Proposition \ref{WhoSwitchesGames}
  \end{proof}
\end{proposition}

\subsection{Categories of transfinite games and strategies}

We want to build a category $\G(\alpha)$ whose objects are games and whose morphisms are strategies on the linear implication of two games.  Given $\alpha$-games $A$, $B$ and $C$ and strategies $\sigma$ for $A\implies B$ and $\tau$ for $B\implies C$, we define
\begin{gather*}
  \sigma\|\tau = \left\{\s\in (M_A\cprd M_B\cprd M_C)^{*<\alpha2}\suchthat \s\vert_{A,B}\in\sigma,\;\s\vert_{B,C}\in\tau\right\}\\
  \comp\tau\sigma = \{\s\vert_{A,C}\suchthat \s\in\sigma\|\tau\}
\end{gather*}

Here, $\alpha2$ is intended to be an upper bound and indeed any sufficiently large ordinal will do without changing the elements of $\sigma\|\tau$.  For the functor $\cmap{\F}{\G(\alpha)}{\Rel}$, we shall want to show that
\[
  \comp\tau\sigma = \left\{s\in P_{A\implies C}\suchthat\exists t\in\sigma,u\in\tau\esuchthat s\vert_A=t\vert_A,\;t\vert_B=u\vert_B,\;s\vert_C=u\vert_C\right\}
  \]
To show this, we will want to show that for any such $s,t,u$ there is some interleaving $\s$ such that $\s\vert_{A,C}=s$, $\s\vert_{A,B}=t$ and $\s\vert_{B,C}=u$.  Even though $s$, $t$ and $u$ all have length less than $\alpha$, $\s$ might have longer length; it will, however, have length less than $\alpha2$.

Note that it is not immediately clear that the elements of $\comp\tau\sigma$ have length less than $\alpha$.  We will have to show this.  First, though, we will need to restrict our class of games so that we do get a well-defined composition.

\subsubsection{Completely negative and almost completely negative $\alpha$-games}

Recall that when defining a finitary game $A=(M_A,\lambda_A,\zeta_A,P_A)$, the function $\zeta_A$ was entirely determined by two pieces of information: the function $\lambda_A$ (to determine $\zeta_A(sa)$ for any non-empty play $sa$) and the designation of the game as either \emph{positive} or \emph{negative} (to determine $\zeta_A(\emptyplay)$).  In the $\omega+1$ case, we also needed to specify a function $\cmap{W_A}{P_A^\infty}{\OP}$ to get the sign of each $\omega$-play.  The general case is similar - once we have specified $\zeta_A(s)$ for any play $s$ whose length is a limit ordinal, the values of $\zeta_A(t)$ for $t$ a play over a successor ordinal are determined by the alternating condition (alternatively, they are determined automatically by well-formedness).  

When building a category of games, we restricted our attention to the negative games.  This is necessary in order to avoid technical complications\footnote{The category in \cite{abramskyjagadeesangames} has both positive and negative games as objects, together with games where either player may start, but it does not admit a faithful functor into $\Rel$ in the way that we want.}.  Of course, these technical complications carry over to the transfinite case, so we need a new negativity condition for our $\alpha$-games.

\begin{definition}
  Let $A$ be an $\alpha$-game.  We say that $A$ is \emph{completely negative} if $\zeta_A(s)=P$ whenever $s\in P_A$ and $\length(s)$ is a limit ordinal.
\end{definition}

Since the only limiting play in the finitary case is the empty play, we see that the completely negative $\omega$-games are precisely the negative games.  But now consider the $\omega+1$ case.  If $A$ is a win-game, then $A$ is completely negative only if it is negative and all infinite plays are $P$-winning.  Recall that we \emph{were} able to build a category of negative win-games without making the requirement that player $P$ wins all infinite plays, so if we insist on complete negativity then we lose much of the richness of our category for no technical benefit.  We would be better off with some weaker condition.

\begin{definition}
  Let $\alpha$ be an ordinal.  If $\alpha=\alpha'+1$ and $A$ is an $\alpha$-game, we say that $s\in P_A$ is \emph{length maximal} if it has the largest possible length - i.e., if $\length(s)=\alpha'$.  

  If $\alpha$ is a limit ordinal then there are no length maximal plays in $\alpha$-games.

  Let $A$ be an $\alpha$-game.  We say that $A$ is \emph{almost completely negative} (\emph{acn}) if $\zeta_A(s)=P$ whenever $\length(s)$ is a limit ordinal \emph{and $s$ is not length-maximal}.
\end{definition}

Note that for most ordinals $\alpha$ there is no difference between being completely negative and being acn.  The only ordinals for which there is  a difference are those of the form $\mu+1$, where $\mu$ is a limit ordinal.  

Our category will have acn $\alpha$-games as objects and the morphisms from $A$ to $B$ will be partial strategies for $A\implies B$.  Later we will consider the total strategy case.

\begin{proposition}
  Let $A,B$ be acn $\alpha$-games.  Then $A\tensor B$ and $A\implies B$ are acn.
  \begin{proof}
    Let $s\in P_{A\tensor B}$ be a limiting play that is not length maximal.  Then at least one of $s\vert_A$ and $s\vert_B$ must be a limiting play (otherwise they both have last moves and the later of the two will be the last move in $s$).  Suppose that $s\vert_A$ and $s\vert_B$ are both limiting plays.  By Lemma \ref{TechnicalOrdinalLemma}, $\length(s\vert_A),\length(s\vert_B)\le\length(s)$, so neither $s\vert_A$ nor $s\vert_B$ is length maximal, since $s$ is not.  Therefore, $\zeta_A(s\vert_A)=\zeta_B(s\vert_B)=P$, since $A$ and $B$ are acn.  Therefore, $\zeta_{A\tensor B}(s)=P$, since $P\wedge P=P$.

    Suppose instead that $s\vert_A$ is a successor play.  Then $s\vert_B$ is a limiting play.  Since $s$ is a limiting play, there must be moves from $B$ in $s$ that occur after the last move in $s\vert_A$.  Therefore, $\zeta_A(s\vert_A)=P$ by Proposition \ref{TransWhoSwitchesGames}.  Now $s\vert_B$ is a limiting play and not length maximal, so $\zeta_B(s\vert_B)=P$ and therefore $\zeta_{A\tensor B}(s)=P$.  The case where $s\vert_B$ is a successor play and $s\vert_A$ is a limiting play is similar.

    Similarly, if $s\in P_{A\implies B}$ is a limiting play that is not length maximal, the equation $(P\Rightarrow P)=P$ proves that $\zeta_{A\implies B}(s)=P$.
  \end{proof}
\end{proposition}

We shall want versions of Proposition \ref{nice-negative-games} and Lemma \ref{alternatingsequenceslemma} to record the properties of negative games that make them so useful for our definition of composition.

\begin{proposition}
  \label{TransNiceNegativeGames}
  \begin{proof}
  \end{proof}
\end{proposition}

\bibliographystyle{alpha}
\bibliography{ordinal_games}

\end{document}
